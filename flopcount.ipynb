{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install fvcore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiADmSZBfzIZ",
        "outputId": "6c23228c-3115-4f38-86e6-08dc80f4c168"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore) (1.26.4)\n",
            "Collecting yacs>=0.1.6 (from fvcore)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fvcore) (4.66.5)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from fvcore) (2.4.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from fvcore) (9.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fvcore) (0.9.0)\n",
            "Collecting iopath>=0.1.7 (from fvcore)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from iopath>=0.1.7->fvcore) (4.12.2)\n",
            "Collecting portalocker (from iopath>=0.1.7->fvcore)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61395 sha256=453637aa94639391627038c43caabc62d7f33b0f4da759d6e8e8e62100024760\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31529 sha256=56d5c932f239d04cdfa9af02fd02a7b00614026805d18787eafeb3706dbe8d90\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: yacs, portalocker, iopath, fvcore\n",
            "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-2.10.1 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "from transformers import BertModel\n",
        "from fvcore.nn import FlopCountAnalysis, flop_count_table, flop_count_str\n",
        "\n",
        "def analyze_model_flops(model, input_tensor, model_name):\n",
        "    flops = FlopCountAnalysis(model, input_tensor)\n",
        "\n",
        "    print(f\"Total FLOPs for {model_name}: {flops.total()}\")\n",
        "\n",
        "    print(f\"FLOPs by operator for {model_name}: {flops.by_operator()}\")\n",
        "\n",
        "    print(f\"FLOPs by module for {model_name}: {flops.by_module()}\")\n",
        "\n",
        "    print(f\"FLOPs by module and operator for {model_name}: {flops.by_module_and_operator()}\")\n",
        "\n",
        "    print(flop_count_table(flops))\n",
        "\n",
        "    print(flop_count_str(flops))\n",
        "\n",
        "dummy_input_cnn = torch.randn(1, 3, 224, 224)\n",
        "dummy_input_bert = torch.randint(0, 30522, (1, 128))"
      ],
      "metadata": {
        "id": "bc4Xi0U8fVxc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
        "vgg16_model.classifier[6] = torch.nn.Linear(in_features=4096, out_features=4)\n",
        "analyze_model_flops(vgg16_model, dummy_input_cnn, \"VGG16\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYdqVelxgLmi",
        "outputId": "9703748f-2c1c-40b8-88a8-b80fc4d89d0a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::max_pool2d encountered 5 time(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total FLOPs for VGG16: 15466209792\n",
            "FLOPs by operator for VGG16: Counter({'conv': 15346630656, 'linear': 119554048, 'adaptive_avg_pool2d': 25088})\n",
            "FLOPs by module for VGG16: Counter({'': 15466209792, 'features': 15346630656, 'features.2': 1849688064, 'features.7': 1849688064, 'features.12': 1849688064, 'features.14': 1849688064, 'features.19': 1849688064, 'features.21': 1849688064, 'features.5': 924844032, 'features.10': 924844032, 'features.17': 924844032, 'features.24': 462422016, 'features.26': 462422016, 'features.28': 462422016, 'classifier': 119554048, 'classifier.0': 102760448, 'features.0': 86704128, 'classifier.3': 16777216, 'avgpool': 25088, 'classifier.6': 16384, 'features.1': 0, 'features.3': 0, 'features.4': 0, 'features.6': 0, 'features.8': 0, 'features.9': 0, 'features.11': 0, 'features.13': 0, 'features.15': 0, 'features.16': 0, 'features.18': 0, 'features.20': 0, 'features.22': 0, 'features.23': 0, 'features.25': 0, 'features.27': 0, 'features.29': 0, 'features.30': 0, 'classifier.1': 0, 'classifier.2': 0, 'classifier.4': 0, 'classifier.5': 0})\n",
            "FLOPs by module and operator for VGG16: {'': Counter({'conv': 15346630656, 'linear': 119554048, 'adaptive_avg_pool2d': 25088}), 'features': Counter({'conv': 15346630656}), 'features.0': Counter({'conv': 86704128}), 'features.1': Counter(), 'features.2': Counter({'conv': 1849688064}), 'features.3': Counter(), 'features.4': Counter(), 'features.5': Counter({'conv': 924844032}), 'features.6': Counter(), 'features.7': Counter({'conv': 1849688064}), 'features.8': Counter(), 'features.9': Counter(), 'features.10': Counter({'conv': 924844032}), 'features.11': Counter(), 'features.12': Counter({'conv': 1849688064}), 'features.13': Counter(), 'features.14': Counter({'conv': 1849688064}), 'features.15': Counter(), 'features.16': Counter(), 'features.17': Counter({'conv': 924844032}), 'features.18': Counter(), 'features.19': Counter({'conv': 1849688064}), 'features.20': Counter(), 'features.21': Counter({'conv': 1849688064}), 'features.22': Counter(), 'features.23': Counter(), 'features.24': Counter({'conv': 462422016}), 'features.25': Counter(), 'features.26': Counter({'conv': 462422016}), 'features.27': Counter(), 'features.28': Counter({'conv': 462422016}), 'features.29': Counter(), 'features.30': Counter(), 'avgpool': Counter({'adaptive_avg_pool2d': 25088}), 'classifier': Counter({'linear': 119554048}), 'classifier.0': Counter({'linear': 102760448}), 'classifier.1': Counter(), 'classifier.2': Counter(), 'classifier.3': Counter({'linear': 16777216}), 'classifier.4': Counter(), 'classifier.5': Counter(), 'classifier.6': Counter({'linear': 16384})}\n",
            "| module                 | #parameters or shape   | #flops    |\n",
            "|:-----------------------|:-----------------------|:----------|\n",
            "| model                  | 0.134G                 | 15.466G   |\n",
            "|  features              |  14.715M               |  15.347G  |\n",
            "|   features.0           |   1.792K               |   86.704M |\n",
            "|    features.0.weight   |    (64, 3, 3, 3)       |           |\n",
            "|    features.0.bias     |    (64,)               |           |\n",
            "|   features.2           |   36.928K              |   1.85G   |\n",
            "|    features.2.weight   |    (64, 64, 3, 3)      |           |\n",
            "|    features.2.bias     |    (64,)               |           |\n",
            "|   features.5           |   73.856K              |   0.925G  |\n",
            "|    features.5.weight   |    (128, 64, 3, 3)     |           |\n",
            "|    features.5.bias     |    (128,)              |           |\n",
            "|   features.7           |   0.148M               |   1.85G   |\n",
            "|    features.7.weight   |    (128, 128, 3, 3)    |           |\n",
            "|    features.7.bias     |    (128,)              |           |\n",
            "|   features.10          |   0.295M               |   0.925G  |\n",
            "|    features.10.weight  |    (256, 128, 3, 3)    |           |\n",
            "|    features.10.bias    |    (256,)              |           |\n",
            "|   features.12          |   0.59M                |   1.85G   |\n",
            "|    features.12.weight  |    (256, 256, 3, 3)    |           |\n",
            "|    features.12.bias    |    (256,)              |           |\n",
            "|   features.14          |   0.59M                |   1.85G   |\n",
            "|    features.14.weight  |    (256, 256, 3, 3)    |           |\n",
            "|    features.14.bias    |    (256,)              |           |\n",
            "|   features.17          |   1.18M                |   0.925G  |\n",
            "|    features.17.weight  |    (512, 256, 3, 3)    |           |\n",
            "|    features.17.bias    |    (512,)              |           |\n",
            "|   features.19          |   2.36M                |   1.85G   |\n",
            "|    features.19.weight  |    (512, 512, 3, 3)    |           |\n",
            "|    features.19.bias    |    (512,)              |           |\n",
            "|   features.21          |   2.36M                |   1.85G   |\n",
            "|    features.21.weight  |    (512, 512, 3, 3)    |           |\n",
            "|    features.21.bias    |    (512,)              |           |\n",
            "|   features.24          |   2.36M                |   0.462G  |\n",
            "|    features.24.weight  |    (512, 512, 3, 3)    |           |\n",
            "|    features.24.bias    |    (512,)              |           |\n",
            "|   features.26          |   2.36M                |   0.462G  |\n",
            "|    features.26.weight  |    (512, 512, 3, 3)    |           |\n",
            "|    features.26.bias    |    (512,)              |           |\n",
            "|   features.28          |   2.36M                |   0.462G  |\n",
            "|    features.28.weight  |    (512, 512, 3, 3)    |           |\n",
            "|    features.28.bias    |    (512,)              |           |\n",
            "|  classifier            |  0.12G                 |  0.12G    |\n",
            "|   classifier.0         |   0.103G               |   0.103G  |\n",
            "|    classifier.0.weight |    (4096, 25088)       |           |\n",
            "|    classifier.0.bias   |    (4096,)             |           |\n",
            "|   classifier.3         |   16.781M              |   16.777M |\n",
            "|    classifier.3.weight |    (4096, 4096)        |           |\n",
            "|    classifier.3.bias   |    (4096,)             |           |\n",
            "|   classifier.6         |   16.388K              |   16.384K |\n",
            "|    classifier.6.weight |    (4, 4096)           |           |\n",
            "|    classifier.6.bias   |    (4,)                |           |\n",
            "|  avgpool               |                        |  25.088K  |\n",
            "VGG(\n",
            "  #params: 0.13G, #flops: 15.47G\n",
            "  (features): Sequential(\n",
            "    #params: 14.71M, #flops: 15.35G\n",
            "    (0): Conv2d(\n",
            "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "      #params: 1.79K, #flops: 86.7M\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "      #params: 36.93K, #flops: 1.85G\n",
            "    )\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(\n",
            "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "      #params: 73.86K, #flops: 0.92G\n",
            "    )\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(\n",
            "      128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "      #params: 0.15M, #flops: 1.85G\n",
            "    )\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(\n",
            "      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "      #params: 0.3M, #flops: 0.92G\n",
            "    )\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "      #params: 0.59M, #flops: 1.85G\n",
            "    )\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "      #params: 0.59M, #flops: 1.85G\n",
            "    )\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(\n",
            "      256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "      #params: 1.18M, #flops: 0.92G\n",
            "    )\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(\n",
            "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "      #params: 2.36M, #flops: 1.85G\n",
            "    )\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(\n",
            "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "      #params: 2.36M, #flops: 1.85G\n",
            "    )\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(\n",
            "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "      #params: 2.36M, #flops: 0.46G\n",
            "    )\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(\n",
            "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "      #params: 2.36M, #flops: 0.46G\n",
            "    )\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(\n",
            "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "      #params: 2.36M, #flops: 0.46G\n",
            "    )\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(\n",
            "    output_size=(7, 7)\n",
            "    #params: 0, #flops: 25.09K\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    #params: 0.12G, #flops: 0.12G\n",
            "    (0): Linear(\n",
            "      in_features=25088, out_features=4096, bias=True\n",
            "      #params: 0.1G, #flops: 0.1G\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(\n",
            "      in_features=4096, out_features=4096, bias=True\n",
            "      #params: 16.78M, #flops: 16.78M\n",
            "    )\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(\n",
            "      in_features=4096, out_features=4, bias=True\n",
            "      #params: 16.39K, #flops: 16.38K\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "resnet50_model.fc = torch.nn.Linear(in_features=2048, out_features=4)\n",
        "analyze_model_flops(resnet50_model, dummy_input_cnn, \"ResNet50\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ1O-dcPgOza",
        "outputId": "ccf8857d-9d6e-4f58-aff3-5c5f0e164f49"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add_ encountered 69 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::max_pool2d encountered 1 time(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total FLOPs for ResNet50: 4142814720\n",
            "FLOPs by operator for ResNet50: Counter({'conv': 4087136256, 'batch_norm': 55569920, 'adaptive_avg_pool2d': 100352, 'linear': 8192})\n",
            "FLOPs by module for ResNet50: Counter({'': 4142814720, 'layer3': 1475124224, 'layer2': 1043159040, 'layer4': 812374528, 'layer1': 690020352, 'layer2.0': 379029504, 'layer3.0': 375768064, 'layer4.0': 374137344, 'layer1.0': 241246208, 'layer1.1': 224387072, 'layer1.2': 224387072, 'layer2.1': 221376512, 'layer2.2': 221376512, 'layer2.3': 221376512, 'layer3.1': 219871232, 'layer3.2': 219871232, 'layer3.3': 219871232, 'layer3.4': 219871232, 'layer3.5': 219871232, 'layer4.1': 219118592, 'layer4.2': 219118592, 'conv1': 118013952, 'layer1.0.conv2': 115605504, 'layer1.1.conv2': 115605504, 'layer1.2.conv2': 115605504, 'layer2.0.conv2': 115605504, 'layer2.1.conv2': 115605504, 'layer2.2.conv2': 115605504, 'layer2.3.conv2': 115605504, 'layer3.0.conv2': 115605504, 'layer3.1.conv2': 115605504, 'layer3.2.conv2': 115605504, 'layer3.3.conv2': 115605504, 'layer3.4.conv2': 115605504, 'layer3.5.conv2': 115605504, 'layer4.0.conv2': 115605504, 'layer4.1.conv2': 115605504, 'layer4.2.conv2': 115605504, 'layer2.0.downsample': 104767488, 'layer3.0.downsample': 103763968, 'layer4.0.downsample': 103262208, 'layer2.0.conv1': 102760448, 'layer2.0.downsample.0': 102760448, 'layer3.0.conv1': 102760448, 'layer3.0.downsample.0': 102760448, 'layer4.0.conv1': 102760448, 'layer4.0.downsample.0': 102760448, 'layer1.0.downsample': 55394304, 'layer1.0.conv3': 51380224, 'layer1.0.downsample.0': 51380224, 'layer1.1.conv1': 51380224, 'layer1.1.conv3': 51380224, 'layer1.2.conv1': 51380224, 'layer1.2.conv3': 51380224, 'layer2.0.conv3': 51380224, 'layer2.1.conv1': 51380224, 'layer2.1.conv3': 51380224, 'layer2.2.conv1': 51380224, 'layer2.2.conv3': 51380224, 'layer2.3.conv1': 51380224, 'layer2.3.conv3': 51380224, 'layer3.0.conv3': 51380224, 'layer3.1.conv1': 51380224, 'layer3.1.conv3': 51380224, 'layer3.2.conv1': 51380224, 'layer3.2.conv3': 51380224, 'layer3.3.conv1': 51380224, 'layer3.3.conv3': 51380224, 'layer3.4.conv1': 51380224, 'layer3.4.conv3': 51380224, 'layer3.5.conv1': 51380224, 'layer3.5.conv3': 51380224, 'layer4.0.conv3': 51380224, 'layer4.1.conv1': 51380224, 'layer4.1.conv3': 51380224, 'layer4.2.conv1': 51380224, 'layer4.2.conv3': 51380224, 'layer1.0.conv1': 12845056, 'bn1': 4014080, 'layer1.0.bn3': 4014080, 'layer1.0.downsample.1': 4014080, 'layer1.1.bn3': 4014080, 'layer1.2.bn3': 4014080, 'layer2.0.bn1': 2007040, 'layer2.0.bn3': 2007040, 'layer2.0.downsample.1': 2007040, 'layer2.1.bn3': 2007040, 'layer2.2.bn3': 2007040, 'layer2.3.bn3': 2007040, 'layer1.0.bn1': 1003520, 'layer1.0.bn2': 1003520, 'layer1.1.bn1': 1003520, 'layer1.1.bn2': 1003520, 'layer1.2.bn1': 1003520, 'layer1.2.bn2': 1003520, 'layer3.0.bn1': 1003520, 'layer3.0.bn3': 1003520, 'layer3.0.downsample.1': 1003520, 'layer3.1.bn3': 1003520, 'layer3.2.bn3': 1003520, 'layer3.3.bn3': 1003520, 'layer3.4.bn3': 1003520, 'layer3.5.bn3': 1003520, 'layer2.0.bn2': 501760, 'layer2.1.bn1': 501760, 'layer2.1.bn2': 501760, 'layer2.2.bn1': 501760, 'layer2.2.bn2': 501760, 'layer2.3.bn1': 501760, 'layer2.3.bn2': 501760, 'layer4.0.bn1': 501760, 'layer4.0.bn3': 501760, 'layer4.0.downsample.1': 501760, 'layer4.1.bn3': 501760, 'layer4.2.bn3': 501760, 'layer3.0.bn2': 250880, 'layer3.1.bn1': 250880, 'layer3.1.bn2': 250880, 'layer3.2.bn1': 250880, 'layer3.2.bn2': 250880, 'layer3.3.bn1': 250880, 'layer3.3.bn2': 250880, 'layer3.4.bn1': 250880, 'layer3.4.bn2': 250880, 'layer3.5.bn1': 250880, 'layer3.5.bn2': 250880, 'layer4.0.bn2': 125440, 'layer4.1.bn1': 125440, 'layer4.1.bn2': 125440, 'layer4.2.bn1': 125440, 'layer4.2.bn2': 125440, 'avgpool': 100352, 'fc': 8192, 'relu': 0, 'maxpool': 0, 'layer1.0.relu': 0, 'layer1.1.relu': 0, 'layer1.2.relu': 0, 'layer2.0.relu': 0, 'layer2.1.relu': 0, 'layer2.2.relu': 0, 'layer2.3.relu': 0, 'layer3.0.relu': 0, 'layer3.1.relu': 0, 'layer3.2.relu': 0, 'layer3.3.relu': 0, 'layer3.4.relu': 0, 'layer3.5.relu': 0, 'layer4.0.relu': 0, 'layer4.1.relu': 0, 'layer4.2.relu': 0})\n",
            "FLOPs by module and operator for ResNet50: {'': Counter({'conv': 4087136256, 'batch_norm': 55569920, 'adaptive_avg_pool2d': 100352, 'linear': 8192}), 'conv1': Counter({'conv': 118013952}), 'bn1': Counter({'batch_norm': 4014080}), 'relu': Counter(), 'maxpool': Counter(), 'layer1': Counter({'conv': 667942912, 'batch_norm': 22077440}), 'layer1.0': Counter({'conv': 231211008, 'batch_norm': 10035200}), 'layer1.0.conv1': Counter({'conv': 12845056}), 'layer1.0.bn1': Counter({'batch_norm': 1003520}), 'layer1.0.conv2': Counter({'conv': 115605504}), 'layer1.0.bn2': Counter({'batch_norm': 1003520}), 'layer1.0.conv3': Counter({'conv': 51380224}), 'layer1.0.bn3': Counter({'batch_norm': 4014080}), 'layer1.0.relu': Counter(), 'layer1.0.downsample': Counter({'conv': 51380224, 'batch_norm': 4014080}), 'layer1.0.downsample.0': Counter({'conv': 51380224}), 'layer1.0.downsample.1': Counter({'batch_norm': 4014080}), 'layer1.1': Counter({'conv': 218365952, 'batch_norm': 6021120}), 'layer1.1.conv1': Counter({'conv': 51380224}), 'layer1.1.bn1': Counter({'batch_norm': 1003520}), 'layer1.1.conv2': Counter({'conv': 115605504}), 'layer1.1.bn2': Counter({'batch_norm': 1003520}), 'layer1.1.conv3': Counter({'conv': 51380224}), 'layer1.1.bn3': Counter({'batch_norm': 4014080}), 'layer1.1.relu': Counter(), 'layer1.2': Counter({'conv': 218365952, 'batch_norm': 6021120}), 'layer1.2.conv1': Counter({'conv': 51380224}), 'layer1.2.bn1': Counter({'batch_norm': 1003520}), 'layer1.2.conv2': Counter({'conv': 115605504}), 'layer1.2.bn2': Counter({'batch_norm': 1003520}), 'layer1.2.conv3': Counter({'conv': 51380224}), 'layer1.2.bn3': Counter({'batch_norm': 4014080}), 'layer1.2.relu': Counter(), 'layer2': Counter({'conv': 1027604480, 'batch_norm': 15554560}), 'layer2.0': Counter({'conv': 372506624, 'batch_norm': 6522880}), 'layer2.0.conv1': Counter({'conv': 102760448}), 'layer2.0.bn1': Counter({'batch_norm': 2007040}), 'layer2.0.conv2': Counter({'conv': 115605504}), 'layer2.0.bn2': Counter({'batch_norm': 501760}), 'layer2.0.conv3': Counter({'conv': 51380224}), 'layer2.0.bn3': Counter({'batch_norm': 2007040}), 'layer2.0.relu': Counter(), 'layer2.0.downsample': Counter({'conv': 102760448, 'batch_norm': 2007040}), 'layer2.0.downsample.0': Counter({'conv': 102760448}), 'layer2.0.downsample.1': Counter({'batch_norm': 2007040}), 'layer2.1': Counter({'conv': 218365952, 'batch_norm': 3010560}), 'layer2.1.conv1': Counter({'conv': 51380224}), 'layer2.1.bn1': Counter({'batch_norm': 501760}), 'layer2.1.conv2': Counter({'conv': 115605504}), 'layer2.1.bn2': Counter({'batch_norm': 501760}), 'layer2.1.conv3': Counter({'conv': 51380224}), 'layer2.1.bn3': Counter({'batch_norm': 2007040}), 'layer2.1.relu': Counter(), 'layer2.2': Counter({'conv': 218365952, 'batch_norm': 3010560}), 'layer2.2.conv1': Counter({'conv': 51380224}), 'layer2.2.bn1': Counter({'batch_norm': 501760}), 'layer2.2.conv2': Counter({'conv': 115605504}), 'layer2.2.bn2': Counter({'batch_norm': 501760}), 'layer2.2.conv3': Counter({'conv': 51380224}), 'layer2.2.bn3': Counter({'batch_norm': 2007040}), 'layer2.2.relu': Counter(), 'layer2.3': Counter({'conv': 218365952, 'batch_norm': 3010560}), 'layer2.3.conv1': Counter({'conv': 51380224}), 'layer2.3.bn1': Counter({'batch_norm': 501760}), 'layer2.3.conv2': Counter({'conv': 115605504}), 'layer2.3.bn2': Counter({'batch_norm': 501760}), 'layer2.3.conv3': Counter({'conv': 51380224}), 'layer2.3.bn3': Counter({'batch_norm': 2007040}), 'layer2.3.relu': Counter(), 'layer3': Counter({'conv': 1464336384, 'batch_norm': 10787840}), 'layer3.0': Counter({'conv': 372506624, 'batch_norm': 3261440}), 'layer3.0.conv1': Counter({'conv': 102760448}), 'layer3.0.bn1': Counter({'batch_norm': 1003520}), 'layer3.0.conv2': Counter({'conv': 115605504}), 'layer3.0.bn2': Counter({'batch_norm': 250880}), 'layer3.0.conv3': Counter({'conv': 51380224}), 'layer3.0.bn3': Counter({'batch_norm': 1003520}), 'layer3.0.relu': Counter(), 'layer3.0.downsample': Counter({'conv': 102760448, 'batch_norm': 1003520}), 'layer3.0.downsample.0': Counter({'conv': 102760448}), 'layer3.0.downsample.1': Counter({'batch_norm': 1003520}), 'layer3.1': Counter({'conv': 218365952, 'batch_norm': 1505280}), 'layer3.1.conv1': Counter({'conv': 51380224}), 'layer3.1.bn1': Counter({'batch_norm': 250880}), 'layer3.1.conv2': Counter({'conv': 115605504}), 'layer3.1.bn2': Counter({'batch_norm': 250880}), 'layer3.1.conv3': Counter({'conv': 51380224}), 'layer3.1.bn3': Counter({'batch_norm': 1003520}), 'layer3.1.relu': Counter(), 'layer3.2': Counter({'conv': 218365952, 'batch_norm': 1505280}), 'layer3.2.conv1': Counter({'conv': 51380224}), 'layer3.2.bn1': Counter({'batch_norm': 250880}), 'layer3.2.conv2': Counter({'conv': 115605504}), 'layer3.2.bn2': Counter({'batch_norm': 250880}), 'layer3.2.conv3': Counter({'conv': 51380224}), 'layer3.2.bn3': Counter({'batch_norm': 1003520}), 'layer3.2.relu': Counter(), 'layer3.3': Counter({'conv': 218365952, 'batch_norm': 1505280}), 'layer3.3.conv1': Counter({'conv': 51380224}), 'layer3.3.bn1': Counter({'batch_norm': 250880}), 'layer3.3.conv2': Counter({'conv': 115605504}), 'layer3.3.bn2': Counter({'batch_norm': 250880}), 'layer3.3.conv3': Counter({'conv': 51380224}), 'layer3.3.bn3': Counter({'batch_norm': 1003520}), 'layer3.3.relu': Counter(), 'layer3.4': Counter({'conv': 218365952, 'batch_norm': 1505280}), 'layer3.4.conv1': Counter({'conv': 51380224}), 'layer3.4.bn1': Counter({'batch_norm': 250880}), 'layer3.4.conv2': Counter({'conv': 115605504}), 'layer3.4.bn2': Counter({'batch_norm': 250880}), 'layer3.4.conv3': Counter({'conv': 51380224}), 'layer3.4.bn3': Counter({'batch_norm': 1003520}), 'layer3.4.relu': Counter(), 'layer3.5': Counter({'conv': 218365952, 'batch_norm': 1505280}), 'layer3.5.conv1': Counter({'conv': 51380224}), 'layer3.5.bn1': Counter({'batch_norm': 250880}), 'layer3.5.conv2': Counter({'conv': 115605504}), 'layer3.5.bn2': Counter({'batch_norm': 250880}), 'layer3.5.conv3': Counter({'conv': 51380224}), 'layer3.5.bn3': Counter({'batch_norm': 1003520}), 'layer3.5.relu': Counter(), 'layer4': Counter({'conv': 809238528, 'batch_norm': 3136000}), 'layer4.0': Counter({'conv': 372506624, 'batch_norm': 1630720}), 'layer4.0.conv1': Counter({'conv': 102760448}), 'layer4.0.bn1': Counter({'batch_norm': 501760}), 'layer4.0.conv2': Counter({'conv': 115605504}), 'layer4.0.bn2': Counter({'batch_norm': 125440}), 'layer4.0.conv3': Counter({'conv': 51380224}), 'layer4.0.bn3': Counter({'batch_norm': 501760}), 'layer4.0.relu': Counter(), 'layer4.0.downsample': Counter({'conv': 102760448, 'batch_norm': 501760}), 'layer4.0.downsample.0': Counter({'conv': 102760448}), 'layer4.0.downsample.1': Counter({'batch_norm': 501760}), 'layer4.1': Counter({'conv': 218365952, 'batch_norm': 752640}), 'layer4.1.conv1': Counter({'conv': 51380224}), 'layer4.1.bn1': Counter({'batch_norm': 125440}), 'layer4.1.conv2': Counter({'conv': 115605504}), 'layer4.1.bn2': Counter({'batch_norm': 125440}), 'layer4.1.conv3': Counter({'conv': 51380224}), 'layer4.1.bn3': Counter({'batch_norm': 501760}), 'layer4.1.relu': Counter(), 'layer4.2': Counter({'conv': 218365952, 'batch_norm': 752640}), 'layer4.2.conv1': Counter({'conv': 51380224}), 'layer4.2.bn1': Counter({'batch_norm': 125440}), 'layer4.2.conv2': Counter({'conv': 115605504}), 'layer4.2.bn2': Counter({'batch_norm': 125440}), 'layer4.2.conv3': Counter({'conv': 51380224}), 'layer4.2.bn3': Counter({'batch_norm': 501760}), 'layer4.2.relu': Counter(), 'avgpool': Counter({'adaptive_avg_pool2d': 100352}), 'fc': Counter({'linear': 8192})}\n",
            "| module                 | #parameters or shape   | #flops     |\n",
            "|:-----------------------|:-----------------------|:-----------|\n",
            "| model                  | 23.516M                | 4.143G     |\n",
            "|  conv1                 |  9.408K                |  0.118G    |\n",
            "|   conv1.weight         |   (64, 3, 7, 7)        |            |\n",
            "|  bn1                   |  0.128K                |  4.014M    |\n",
            "|   bn1.weight           |   (64,)                |            |\n",
            "|   bn1.bias             |   (64,)                |            |\n",
            "|  layer1                |  0.216M                |  0.69G     |\n",
            "|   layer1.0             |   75.008K              |   0.241G   |\n",
            "|    layer1.0.conv1      |    4.096K              |    12.845M |\n",
            "|    layer1.0.bn1        |    0.128K              |    1.004M  |\n",
            "|    layer1.0.conv2      |    36.864K             |    0.116G  |\n",
            "|    layer1.0.bn2        |    0.128K              |    1.004M  |\n",
            "|    layer1.0.conv3      |    16.384K             |    51.38M  |\n",
            "|    layer1.0.bn3        |    0.512K              |    4.014M  |\n",
            "|    layer1.0.downsample |    16.896K             |    55.394M |\n",
            "|   layer1.1             |   70.4K                |   0.224G   |\n",
            "|    layer1.1.conv1      |    16.384K             |    51.38M  |\n",
            "|    layer1.1.bn1        |    0.128K              |    1.004M  |\n",
            "|    layer1.1.conv2      |    36.864K             |    0.116G  |\n",
            "|    layer1.1.bn2        |    0.128K              |    1.004M  |\n",
            "|    layer1.1.conv3      |    16.384K             |    51.38M  |\n",
            "|    layer1.1.bn3        |    0.512K              |    4.014M  |\n",
            "|   layer1.2             |   70.4K                |   0.224G   |\n",
            "|    layer1.2.conv1      |    16.384K             |    51.38M  |\n",
            "|    layer1.2.bn1        |    0.128K              |    1.004M  |\n",
            "|    layer1.2.conv2      |    36.864K             |    0.116G  |\n",
            "|    layer1.2.bn2        |    0.128K              |    1.004M  |\n",
            "|    layer1.2.conv3      |    16.384K             |    51.38M  |\n",
            "|    layer1.2.bn3        |    0.512K              |    4.014M  |\n",
            "|  layer2                |  1.22M                 |  1.043G    |\n",
            "|   layer2.0             |   0.379M               |   0.379G   |\n",
            "|    layer2.0.conv1      |    32.768K             |    0.103G  |\n",
            "|    layer2.0.bn1        |    0.256K              |    2.007M  |\n",
            "|    layer2.0.conv2      |    0.147M              |    0.116G  |\n",
            "|    layer2.0.bn2        |    0.256K              |    0.502M  |\n",
            "|    layer2.0.conv3      |    65.536K             |    51.38M  |\n",
            "|    layer2.0.bn3        |    1.024K              |    2.007M  |\n",
            "|    layer2.0.downsample |    0.132M              |    0.105G  |\n",
            "|   layer2.1             |   0.28M                |   0.221G   |\n",
            "|    layer2.1.conv1      |    65.536K             |    51.38M  |\n",
            "|    layer2.1.bn1        |    0.256K              |    0.502M  |\n",
            "|    layer2.1.conv2      |    0.147M              |    0.116G  |\n",
            "|    layer2.1.bn2        |    0.256K              |    0.502M  |\n",
            "|    layer2.1.conv3      |    65.536K             |    51.38M  |\n",
            "|    layer2.1.bn3        |    1.024K              |    2.007M  |\n",
            "|   layer2.2             |   0.28M                |   0.221G   |\n",
            "|    layer2.2.conv1      |    65.536K             |    51.38M  |\n",
            "|    layer2.2.bn1        |    0.256K              |    0.502M  |\n",
            "|    layer2.2.conv2      |    0.147M              |    0.116G  |\n",
            "|    layer2.2.bn2        |    0.256K              |    0.502M  |\n",
            "|    layer2.2.conv3      |    65.536K             |    51.38M  |\n",
            "|    layer2.2.bn3        |    1.024K              |    2.007M  |\n",
            "|   layer2.3             |   0.28M                |   0.221G   |\n",
            "|    layer2.3.conv1      |    65.536K             |    51.38M  |\n",
            "|    layer2.3.bn1        |    0.256K              |    0.502M  |\n",
            "|    layer2.3.conv2      |    0.147M              |    0.116G  |\n",
            "|    layer2.3.bn2        |    0.256K              |    0.502M  |\n",
            "|    layer2.3.conv3      |    65.536K             |    51.38M  |\n",
            "|    layer2.3.bn3        |    1.024K              |    2.007M  |\n",
            "|  layer3                |  7.098M                |  1.475G    |\n",
            "|   layer3.0             |   1.512M               |   0.376G   |\n",
            "|    layer3.0.conv1      |    0.131M              |    0.103G  |\n",
            "|    layer3.0.bn1        |    0.512K              |    1.004M  |\n",
            "|    layer3.0.conv2      |    0.59M               |    0.116G  |\n",
            "|    layer3.0.bn2        |    0.512K              |    0.251M  |\n",
            "|    layer3.0.conv3      |    0.262M              |    51.38M  |\n",
            "|    layer3.0.bn3        |    2.048K              |    1.004M  |\n",
            "|    layer3.0.downsample |    0.526M              |    0.104G  |\n",
            "|   layer3.1             |   1.117M               |   0.22G    |\n",
            "|    layer3.1.conv1      |    0.262M              |    51.38M  |\n",
            "|    layer3.1.bn1        |    0.512K              |    0.251M  |\n",
            "|    layer3.1.conv2      |    0.59M               |    0.116G  |\n",
            "|    layer3.1.bn2        |    0.512K              |    0.251M  |\n",
            "|    layer3.1.conv3      |    0.262M              |    51.38M  |\n",
            "|    layer3.1.bn3        |    2.048K              |    1.004M  |\n",
            "|   layer3.2             |   1.117M               |   0.22G    |\n",
            "|    layer3.2.conv1      |    0.262M              |    51.38M  |\n",
            "|    layer3.2.bn1        |    0.512K              |    0.251M  |\n",
            "|    layer3.2.conv2      |    0.59M               |    0.116G  |\n",
            "|    layer3.2.bn2        |    0.512K              |    0.251M  |\n",
            "|    layer3.2.conv3      |    0.262M              |    51.38M  |\n",
            "|    layer3.2.bn3        |    2.048K              |    1.004M  |\n",
            "|   layer3.3             |   1.117M               |   0.22G    |\n",
            "|    layer3.3.conv1      |    0.262M              |    51.38M  |\n",
            "|    layer3.3.bn1        |    0.512K              |    0.251M  |\n",
            "|    layer3.3.conv2      |    0.59M               |    0.116G  |\n",
            "|    layer3.3.bn2        |    0.512K              |    0.251M  |\n",
            "|    layer3.3.conv3      |    0.262M              |    51.38M  |\n",
            "|    layer3.3.bn3        |    2.048K              |    1.004M  |\n",
            "|   layer3.4             |   1.117M               |   0.22G    |\n",
            "|    layer3.4.conv1      |    0.262M              |    51.38M  |\n",
            "|    layer3.4.bn1        |    0.512K              |    0.251M  |\n",
            "|    layer3.4.conv2      |    0.59M               |    0.116G  |\n",
            "|    layer3.4.bn2        |    0.512K              |    0.251M  |\n",
            "|    layer3.4.conv3      |    0.262M              |    51.38M  |\n",
            "|    layer3.4.bn3        |    2.048K              |    1.004M  |\n",
            "|   layer3.5             |   1.117M               |   0.22G    |\n",
            "|    layer3.5.conv1      |    0.262M              |    51.38M  |\n",
            "|    layer3.5.bn1        |    0.512K              |    0.251M  |\n",
            "|    layer3.5.conv2      |    0.59M               |    0.116G  |\n",
            "|    layer3.5.bn2        |    0.512K              |    0.251M  |\n",
            "|    layer3.5.conv3      |    0.262M              |    51.38M  |\n",
            "|    layer3.5.bn3        |    2.048K              |    1.004M  |\n",
            "|  layer4                |  14.965M               |  0.812G    |\n",
            "|   layer4.0             |   6.04M                |   0.374G   |\n",
            "|    layer4.0.conv1      |    0.524M              |    0.103G  |\n",
            "|    layer4.0.bn1        |    1.024K              |    0.502M  |\n",
            "|    layer4.0.conv2      |    2.359M              |    0.116G  |\n",
            "|    layer4.0.bn2        |    1.024K              |    0.125M  |\n",
            "|    layer4.0.conv3      |    1.049M              |    51.38M  |\n",
            "|    layer4.0.bn3        |    4.096K              |    0.502M  |\n",
            "|    layer4.0.downsample |    2.101M              |    0.103G  |\n",
            "|   layer4.1             |   4.463M               |   0.219G   |\n",
            "|    layer4.1.conv1      |    1.049M              |    51.38M  |\n",
            "|    layer4.1.bn1        |    1.024K              |    0.125M  |\n",
            "|    layer4.1.conv2      |    2.359M              |    0.116G  |\n",
            "|    layer4.1.bn2        |    1.024K              |    0.125M  |\n",
            "|    layer4.1.conv3      |    1.049M              |    51.38M  |\n",
            "|    layer4.1.bn3        |    4.096K              |    0.502M  |\n",
            "|   layer4.2             |   4.463M               |   0.219G   |\n",
            "|    layer4.2.conv1      |    1.049M              |    51.38M  |\n",
            "|    layer4.2.bn1        |    1.024K              |    0.125M  |\n",
            "|    layer4.2.conv2      |    2.359M              |    0.116G  |\n",
            "|    layer4.2.bn2        |    1.024K              |    0.125M  |\n",
            "|    layer4.2.conv3      |    1.049M              |    51.38M  |\n",
            "|    layer4.2.bn3        |    4.096K              |    0.502M  |\n",
            "|  fc                    |  8.196K                |  8.192K    |\n",
            "|   fc.weight            |   (4, 2048)            |            |\n",
            "|   fc.bias              |   (4,)                 |            |\n",
            "|  avgpool               |                        |  0.1M      |\n",
            "ResNet(\n",
            "  #params: 23.52M, #flops: 4.14G\n",
            "  (conv1): Conv2d(\n",
            "    3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "    #params: 9.41K, #flops: 0.12G\n",
            "  )\n",
            "  (bn1): BatchNorm2d(\n",
            "    64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "    #params: 0.13K, #flops: 4.01M\n",
            "  )\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    #params: 0.22M, #flops: 0.69G\n",
            "    (0): Bottleneck(\n",
            "      #params: 75.01K, #flops: 0.24G\n",
            "      (conv1): Conv2d(\n",
            "        64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 4.1K, #flops: 12.85M\n",
            "      )\n",
            "      (bn1): BatchNorm2d(\n",
            "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.13K, #flops: 1M\n",
            "      )\n",
            "      (conv2): Conv2d(\n",
            "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        #params: 36.86K, #flops: 0.12G\n",
            "      )\n",
            "      (bn2): BatchNorm2d(\n",
            "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.13K, #flops: 1M\n",
            "      )\n",
            "      (conv3): Conv2d(\n",
            "        64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 16.38K, #flops: 51.38M\n",
            "      )\n",
            "      (bn3): BatchNorm2d(\n",
            "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.51K, #flops: 4.01M\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        #params: 16.9K, #flops: 55.39M\n",
            "        (0): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 16.38K, #flops: 51.38M\n",
            "        )\n",
            "        (1): BatchNorm2d(\n",
            "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.51K, #flops: 4.01M\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      #params: 70.4K, #flops: 0.22G\n",
            "      (conv1): Conv2d(\n",
            "        256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 16.38K, #flops: 51.38M\n",
            "      )\n",
            "      (bn1): BatchNorm2d(\n",
            "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.13K, #flops: 1M\n",
            "      )\n",
            "      (conv2): Conv2d(\n",
            "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        #params: 36.86K, #flops: 0.12G\n",
            "      )\n",
            "      (bn2): BatchNorm2d(\n",
            "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.13K, #flops: 1M\n",
            "      )\n",
            "      (conv3): Conv2d(\n",
            "        64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 16.38K, #flops: 51.38M\n",
            "      )\n",
            "      (bn3): BatchNorm2d(\n",
            "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.51K, #flops: 4.01M\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      #params: 70.4K, #flops: 0.22G\n",
            "      (conv1): Conv2d(\n",
            "        256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 16.38K, #flops: 51.38M\n",
            "      )\n",
            "      (bn1): BatchNorm2d(\n",
            "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.13K, #flops: 1M\n",
            "      )\n",
            "      (conv2): Conv2d(\n",
            "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        #params: 36.86K, #flops: 0.12G\n",
            "      )\n",
            "      (bn2): BatchNorm2d(\n",
            "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.13K, #flops: 1M\n",
            "      )\n",
            "      (conv3): Conv2d(\n",
            "        64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 16.38K, #flops: 51.38M\n",
            "      )\n",
            "      (bn3): BatchNorm2d(\n",
            "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.51K, #flops: 4.01M\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    #params: 1.22M, #flops: 1.04G\n",
            "    (0): Bottleneck(\n",
            "      #params: 0.38M, #flops: 0.38G\n",
            "      (conv1): Conv2d(\n",
            "        256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 32.77K, #flops: 0.1G\n",
            "      )\n",
            "      (bn1): BatchNorm2d(\n",
            "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.26K, #flops: 2.01M\n",
            "      )\n",
            "      (conv2): Conv2d(\n",
            "        128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "        #params: 0.15M, #flops: 0.12G\n",
            "      )\n",
            "      (bn2): BatchNorm2d(\n",
            "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.26K, #flops: 0.5M\n",
            "      )\n",
            "      (conv3): Conv2d(\n",
            "        128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 65.54K, #flops: 51.38M\n",
            "      )\n",
            "      (bn3): BatchNorm2d(\n",
            "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 1.02K, #flops: 2.01M\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        #params: 0.13M, #flops: 0.1G\n",
            "        (0): Conv2d(\n",
            "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          #params: 0.13M, #flops: 0.1G\n",
            "        )\n",
            "        (1): BatchNorm2d(\n",
            "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.02K, #flops: 2.01M\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      #params: 0.28M, #flops: 0.22G\n",
            "      (conv1): Conv2d(\n",
            "        512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 65.54K, #flops: 51.38M\n",
            "      )\n",
            "      (bn1): BatchNorm2d(\n",
            "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.26K, #flops: 0.5M\n",
            "      )\n",
            "      (conv2): Conv2d(\n",
            "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        #params: 0.15M, #flops: 0.12G\n",
            "      )\n",
            "      (bn2): BatchNorm2d(\n",
            "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.26K, #flops: 0.5M\n",
            "      )\n",
            "      (conv3): Conv2d(\n",
            "        128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 65.54K, #flops: 51.38M\n",
            "      )\n",
            "      (bn3): BatchNorm2d(\n",
            "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 1.02K, #flops: 2.01M\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      #params: 0.28M, #flops: 0.22G\n",
            "      (conv1): Conv2d(\n",
            "        512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 65.54K, #flops: 51.38M\n",
            "      )\n",
            "      (bn1): BatchNorm2d(\n",
            "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.26K, #flops: 0.5M\n",
            "      )\n",
            "      (conv2): Conv2d(\n",
            "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        #params: 0.15M, #flops: 0.12G\n",
            "      )\n",
            "      (bn2): BatchNorm2d(\n",
            "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.26K, #flops: 0.5M\n",
            "      )\n",
            "      (conv3): Conv2d(\n",
            "        128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 65.54K, #flops: 51.38M\n",
            "      )\n",
            "      (bn3): BatchNorm2d(\n",
            "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 1.02K, #flops: 2.01M\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      #params: 0.28M, #flops: 0.22G\n",
            "      (conv1): Conv2d(\n",
            "        512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 65.54K, #flops: 51.38M\n",
            "      )\n",
            "      (bn1): BatchNorm2d(\n",
            "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.26K, #flops: 0.5M\n",
            "      )\n",
            "      (conv2): Conv2d(\n",
            "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        #params: 0.15M, #flops: 0.12G\n",
            "      )\n",
            "      (bn2): BatchNorm2d(\n",
            "        128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.26K, #flops: 0.5M\n",
            "      )\n",
            "      (conv3): Conv2d(\n",
            "        128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 65.54K, #flops: 51.38M\n",
            "      )\n",
            "      (bn3): BatchNorm2d(\n",
            "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 1.02K, #flops: 2.01M\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    #params: 7.1M, #flops: 1.48G\n",
            "    (0): Bottleneck(\n",
            "      #params: 1.51M, #flops: 0.38G\n",
            "      (conv1): Conv2d(\n",
            "        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 0.13M, #flops: 0.1G\n",
            "      )\n",
            "      (bn1): BatchNorm2d(\n",
            "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.51K, #flops: 1M\n",
            "      )\n",
            "      (conv2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "        #params: 0.59M, #flops: 0.12G\n",
            "      )\n",
            "      (bn2): BatchNorm2d(\n",
            "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.51K, #flops: 0.25M\n",
            "      )\n",
            "      (conv3): Conv2d(\n",
            "        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 0.26M, #flops: 51.38M\n",
            "      )\n",
            "      (bn3): BatchNorm2d(\n",
            "        1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 2.05K, #flops: 1M\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        #params: 0.53M, #flops: 0.1G\n",
            "        (0): Conv2d(\n",
            "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          #params: 0.52M, #flops: 0.1G\n",
            "        )\n",
            "        (1): BatchNorm2d(\n",
            "          1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 2.05K, #flops: 1M\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      #params: 1.12M, #flops: 0.22G\n",
            "      (conv1): Conv2d(\n",
            "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 0.26M, #flops: 51.38M\n",
            "      )\n",
            "      (bn1): BatchNorm2d(\n",
            "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.51K, #flops: 0.25M\n",
            "      )\n",
            "      (conv2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        #params: 0.59M, #flops: 0.12G\n",
            "      )\n",
            "      (bn2): BatchNorm2d(\n",
            "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.51K, #flops: 0.25M\n",
            "      )\n",
            "      (conv3): Conv2d(\n",
            "        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 0.26M, #flops: 51.38M\n",
            "      )\n",
            "      (bn3): BatchNorm2d(\n",
            "        1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 2.05K, #flops: 1M\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      #params: 1.12M, #flops: 0.22G\n",
            "      (conv1): Conv2d(\n",
            "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 0.26M, #flops: 51.38M\n",
            "      )\n",
            "      (bn1): BatchNorm2d(\n",
            "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.51K, #flops: 0.25M\n",
            "      )\n",
            "      (conv2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        #params: 0.59M, #flops: 0.12G\n",
            "      )\n",
            "      (bn2): BatchNorm2d(\n",
            "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.51K, #flops: 0.25M\n",
            "      )\n",
            "      (conv3): Conv2d(\n",
            "        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 0.26M, #flops: 51.38M\n",
            "      )\n",
            "      (bn3): BatchNorm2d(\n",
            "        1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 2.05K, #flops: 1M\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      #params: 1.12M, #flops: 0.22G\n",
            "      (conv1): Conv2d(\n",
            "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 0.26M, #flops: 51.38M\n",
            "      )\n",
            "      (bn1): BatchNorm2d(\n",
            "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.51K, #flops: 0.25M\n",
            "      )\n",
            "      (conv2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        #params: 0.59M, #flops: 0.12G\n",
            "      )\n",
            "      (bn2): BatchNorm2d(\n",
            "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.51K, #flops: 0.25M\n",
            "      )\n",
            "      (conv3): Conv2d(\n",
            "        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 0.26M, #flops: 51.38M\n",
            "      )\n",
            "      (bn3): BatchNorm2d(\n",
            "        1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 2.05K, #flops: 1M\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      #params: 1.12M, #flops: 0.22G\n",
            "      (conv1): Conv2d(\n",
            "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 0.26M, #flops: 51.38M\n",
            "      )\n",
            "      (bn1): BatchNorm2d(\n",
            "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.51K, #flops: 0.25M\n",
            "      )\n",
            "      (conv2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        #params: 0.59M, #flops: 0.12G\n",
            "      )\n",
            "      (bn2): BatchNorm2d(\n",
            "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.51K, #flops: 0.25M\n",
            "      )\n",
            "      (conv3): Conv2d(\n",
            "        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 0.26M, #flops: 51.38M\n",
            "      )\n",
            "      (bn3): BatchNorm2d(\n",
            "        1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 2.05K, #flops: 1M\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      #params: 1.12M, #flops: 0.22G\n",
            "      (conv1): Conv2d(\n",
            "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 0.26M, #flops: 51.38M\n",
            "      )\n",
            "      (bn1): BatchNorm2d(\n",
            "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.51K, #flops: 0.25M\n",
            "      )\n",
            "      (conv2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        #params: 0.59M, #flops: 0.12G\n",
            "      )\n",
            "      (bn2): BatchNorm2d(\n",
            "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.51K, #flops: 0.25M\n",
            "      )\n",
            "      (conv3): Conv2d(\n",
            "        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 0.26M, #flops: 51.38M\n",
            "      )\n",
            "      (bn3): BatchNorm2d(\n",
            "        1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 2.05K, #flops: 1M\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    #params: 14.96M, #flops: 0.81G\n",
            "    (0): Bottleneck(\n",
            "      #params: 6.04M, #flops: 0.37G\n",
            "      (conv1): Conv2d(\n",
            "        1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 0.52M, #flops: 0.1G\n",
            "      )\n",
            "      (bn1): BatchNorm2d(\n",
            "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 1.02K, #flops: 0.5M\n",
            "      )\n",
            "      (conv2): Conv2d(\n",
            "        512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "        #params: 2.36M, #flops: 0.12G\n",
            "      )\n",
            "      (bn2): BatchNorm2d(\n",
            "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 1.02K, #flops: 0.13M\n",
            "      )\n",
            "      (conv3): Conv2d(\n",
            "        512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 1.05M, #flops: 51.38M\n",
            "      )\n",
            "      (bn3): BatchNorm2d(\n",
            "        2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 4.1K, #flops: 0.5M\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        #params: 2.1M, #flops: 0.1G\n",
            "        (0): Conv2d(\n",
            "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          #params: 2.1M, #flops: 0.1G\n",
            "        )\n",
            "        (1): BatchNorm2d(\n",
            "          2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 4.1K, #flops: 0.5M\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      #params: 4.46M, #flops: 0.22G\n",
            "      (conv1): Conv2d(\n",
            "        2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 1.05M, #flops: 51.38M\n",
            "      )\n",
            "      (bn1): BatchNorm2d(\n",
            "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 1.02K, #flops: 0.13M\n",
            "      )\n",
            "      (conv2): Conv2d(\n",
            "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        #params: 2.36M, #flops: 0.12G\n",
            "      )\n",
            "      (bn2): BatchNorm2d(\n",
            "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 1.02K, #flops: 0.13M\n",
            "      )\n",
            "      (conv3): Conv2d(\n",
            "        512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 1.05M, #flops: 51.38M\n",
            "      )\n",
            "      (bn3): BatchNorm2d(\n",
            "        2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 4.1K, #flops: 0.5M\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      #params: 4.46M, #flops: 0.22G\n",
            "      (conv1): Conv2d(\n",
            "        2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 1.05M, #flops: 51.38M\n",
            "      )\n",
            "      (bn1): BatchNorm2d(\n",
            "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 1.02K, #flops: 0.13M\n",
            "      )\n",
            "      (conv2): Conv2d(\n",
            "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        #params: 2.36M, #flops: 0.12G\n",
            "      )\n",
            "      (bn2): BatchNorm2d(\n",
            "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 1.02K, #flops: 0.13M\n",
            "      )\n",
            "      (conv3): Conv2d(\n",
            "        512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 1.05M, #flops: 51.38M\n",
            "      )\n",
            "      (bn3): BatchNorm2d(\n",
            "        2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 4.1K, #flops: 0.5M\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(\n",
            "    output_size=(1, 1)\n",
            "    #params: 0, #flops: 0.1M\n",
            "  )\n",
            "  (fc): Linear(\n",
            "    in_features=2048, out_features=4, bias=True\n",
            "    #params: 8.2K, #flops: 8.19K\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "densenet121_model = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
        "densenet121_model.classifier = torch.nn.Linear(in_features=1024, out_features=4)\n",
        "analyze_model_flops(densenet121_model, dummy_input_cnn, \"DenseNet121\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQjzbhcagPFa",
        "outputId": "59ddafb5-5ec8-4401-f94e-12ecbd0a9139"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add_ encountered 121 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::max_pool2d encountered 1 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::avg_pool2d encountered 3 time(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total FLOPs for DenseNet121: 2911529216\n",
            "FLOPs by operator for DenseNet121: Counter({'conv': 2833137664, 'batch_norm': 78337280, 'adaptive_avg_pool2d': 50176, 'linear': 4096})\n",
            "FLOPs by module for DenseNet121: Counter({'': 2911529216, 'features': 2911474944, 'features.denseblock1': 1066039296, 'features.denseblock2': 733221888, 'features.denseblock3': 566813184, 'features.denseblock1.denselayer6': 211040256, 'features.denseblock1.denselayer5': 197693440, 'features.denseblock1.denselayer4': 184346624, 'features.denseblock1.denselayer3': 170999808, 'features.denseblock1.denselayer2': 157652992, 'features.denseblock1.denselayer1': 144306176, 'features.conv0': 118013952, 'features.denseblock1.denselayer1.conv2': 115605504, 'features.denseblock1.denselayer2.conv2': 115605504, 'features.denseblock1.denselayer3.conv2': 115605504, 'features.denseblock1.denselayer4.conv2': 115605504, 'features.denseblock1.denselayer5.conv2': 115605504, 'features.denseblock1.denselayer6.conv2': 115605504, 'features.denseblock4': 107815680, 'features.transition1': 106774528, 'features.transition2': 104767488, 'features.transition3': 103763968, 'features.transition1.conv': 102760448, 'features.transition2.conv': 102760448, 'features.transition3.conv': 102760448, 'features.denseblock1.denselayer6.conv1': 89915392, 'features.denseblock2.denselayer12': 79453696, 'features.denseblock1.denselayer5.conv1': 77070336, 'features.denseblock2.denselayer11': 76116992, 'features.denseblock2.denselayer10': 72780288, 'features.denseblock2.denselayer9': 69443584, 'features.denseblock2.denselayer8': 66106880, 'features.denseblock1.denselayer4.conv1': 64225280, 'features.denseblock2.denselayer7': 62770176, 'features.denseblock2.denselayer6': 59433472, 'features.denseblock2.denselayer5': 56096768, 'features.denseblock2.denselayer4': 52760064, 'features.denseblock1.denselayer3.conv1': 51380224, 'features.denseblock2.denselayer3': 49423360, 'features.denseblock2.denselayer12.conv1': 48168960, 'features.denseblock2.denselayer2': 46086656, 'features.denseblock2.denselayer11.conv1': 44957696, 'features.denseblock2.denselayer1': 42749952, 'features.denseblock2.denselayer10.conv1': 41746432, 'features.denseblock1.denselayer2.conv1': 38535168, 'features.denseblock2.denselayer9.conv1': 38535168, 'features.denseblock2.denselayer8.conv1': 35323904, 'features.denseblock3.denselayer24': 33210240, 'features.denseblock3.denselayer23': 32376064, 'features.denseblock2.denselayer7.conv1': 32112640, 'features.denseblock3.denselayer22': 31541888, 'features.denseblock3.denselayer21': 30707712, 'features.denseblock3.denselayer20': 29873536, 'features.denseblock3.denselayer19': 29039360, 'features.denseblock2.denselayer1.conv2': 28901376, 'features.denseblock2.denselayer2.conv2': 28901376, 'features.denseblock2.denselayer3.conv2': 28901376, 'features.denseblock2.denselayer4.conv2': 28901376, 'features.denseblock2.denselayer5.conv2': 28901376, 'features.denseblock2.denselayer6.conv1': 28901376, 'features.denseblock2.denselayer6.conv2': 28901376, 'features.denseblock2.denselayer7.conv2': 28901376, 'features.denseblock2.denselayer8.conv2': 28901376, 'features.denseblock2.denselayer9.conv2': 28901376, 'features.denseblock2.denselayer10.conv2': 28901376, 'features.denseblock2.denselayer11.conv2': 28901376, 'features.denseblock2.denselayer12.conv2': 28901376, 'features.denseblock3.denselayer18': 28205184, 'features.denseblock3.denselayer17': 27371008, 'features.denseblock3.denselayer16': 26536832, 'features.denseblock3.denselayer15': 25702656, 'features.denseblock1.denselayer1.conv1': 25690112, 'features.denseblock2.denselayer5.conv1': 25690112, 'features.denseblock3.denselayer24.conv1': 24887296, 'features.denseblock3.denselayer14': 24868480, 'features.denseblock3.denselayer23.conv1': 24084480, 'features.denseblock3.denselayer13': 24034304, 'features.denseblock3.denselayer22.conv1': 23281664, 'features.denseblock3.denselayer12': 23200128, 'features.denseblock2.denselayer4.conv1': 22478848, 'features.denseblock3.denselayer21.conv1': 22478848, 'features.denseblock3.denselayer11': 22365952, 'features.denseblock3.denselayer20.conv1': 21676032, 'features.denseblock3.denselayer10': 21531776, 'features.denseblock3.denselayer19.conv1': 20873216, 'features.denseblock3.denselayer9': 20697600, 'features.denseblock3.denselayer18.conv1': 20070400, 'features.denseblock3.denselayer8': 19863424, 'features.denseblock2.denselayer3.conv1': 19267584, 'features.denseblock3.denselayer17.conv1': 19267584, 'features.denseblock3.denselayer7': 19029248, 'features.denseblock3.denselayer16.conv1': 18464768, 'features.denseblock3.denselayer6': 18195072, 'features.denseblock3.denselayer15.conv1': 17661952, 'features.denseblock3.denselayer5': 17360896, 'features.denseblock3.denselayer14.conv1': 16859136, 'features.denseblock3.denselayer4': 16526720, 'features.denseblock2.denselayer2.conv1': 16056320, 'features.denseblock3.denselayer13.conv1': 16056320, 'features.denseblock3.denselayer3': 15692544, 'features.denseblock3.denselayer12.conv1': 15253504, 'features.denseblock3.denselayer2': 14858368, 'features.denseblock3.denselayer11.conv1': 14450688, 'features.denseblock3.denselayer1': 14024192, 'features.denseblock3.denselayer10.conv1': 13647872, 'features.denseblock2.denselayer1.conv1': 12845056, 'features.denseblock3.denselayer9.conv1': 12845056, 'features.denseblock3.denselayer8.conv1': 12042240, 'features.denseblock3.denselayer7.conv1': 11239424, 'features.denseblock3.denselayer6.conv1': 10436608, 'features.denseblock3.denselayer5.conv1': 9633792, 'features.denseblock3.denselayer4.conv1': 8830976, 'features.denseblock4.denselayer16': 8302560, 'features.denseblock4.denselayer15': 8094016, 'features.denseblock3.denselayer3.conv1': 8028160, 'features.denseblock4.denselayer14': 7885472, 'features.denseblock4.denselayer13': 7676928, 'features.denseblock4.denselayer12': 7468384, 'features.denseblock4.denselayer11': 7259840, 'features.denseblock3.denselayer1.conv2': 7225344, 'features.denseblock3.denselayer2.conv1': 7225344, 'features.denseblock3.denselayer2.conv2': 7225344, 'features.denseblock3.denselayer3.conv2': 7225344, 'features.denseblock3.denselayer4.conv2': 7225344, 'features.denseblock3.denselayer5.conv2': 7225344, 'features.denseblock3.denselayer6.conv2': 7225344, 'features.denseblock3.denselayer7.conv2': 7225344, 'features.denseblock3.denselayer8.conv2': 7225344, 'features.denseblock3.denselayer9.conv2': 7225344, 'features.denseblock3.denselayer10.conv2': 7225344, 'features.denseblock3.denselayer11.conv2': 7225344, 'features.denseblock3.denselayer12.conv2': 7225344, 'features.denseblock3.denselayer13.conv2': 7225344, 'features.denseblock3.denselayer14.conv2': 7225344, 'features.denseblock3.denselayer15.conv2': 7225344, 'features.denseblock3.denselayer16.conv2': 7225344, 'features.denseblock3.denselayer17.conv2': 7225344, 'features.denseblock3.denselayer18.conv2': 7225344, 'features.denseblock3.denselayer19.conv2': 7225344, 'features.denseblock3.denselayer20.conv2': 7225344, 'features.denseblock3.denselayer21.conv2': 7225344, 'features.denseblock3.denselayer22.conv2': 7225344, 'features.denseblock3.denselayer23.conv2': 7225344, 'features.denseblock3.denselayer24.conv2': 7225344, 'features.denseblock4.denselayer10': 7051296, 'features.denseblock4.denselayer9': 6842752, 'features.denseblock4.denselayer8': 6634208, 'features.denseblock4.denselayer7': 6425664, 'features.denseblock3.denselayer1.conv1': 6422528, 'features.denseblock4.denselayer16.conv1': 6221824, 'features.denseblock4.denselayer6': 6217120, 'features.denseblock4.denselayer15.conv1': 6021120, 'features.denseblock4.denselayer5': 6008576, 'features.denseblock4.denselayer14.conv1': 5820416, 'features.denseblock4.denselayer4': 5800032, 'features.denseblock4.denselayer13.conv1': 5619712, 'features.denseblock4.denselayer3': 5591488, 'features.denseblock4.denselayer12.conv1': 5419008, 'features.denseblock4.denselayer2': 5382944, 'features.denseblock4.denselayer11.conv1': 5218304, 'features.denseblock4.denselayer1': 5174400, 'features.denseblock4.denselayer10.conv1': 5017600, 'features.denseblock4.denselayer9.conv1': 4816896, 'features.denseblock4.denselayer8.conv1': 4616192, 'features.denseblock4.denselayer7.conv1': 4415488, 'features.denseblock4.denselayer6.conv1': 4214784, 'features.norm0': 4014080, 'features.transition1.norm': 4014080, 'features.denseblock4.denselayer5.conv1': 4014080, 'features.denseblock4.denselayer4.conv1': 3813376, 'features.denseblock4.denselayer3.conv1': 3612672, 'features.denseblock1.denselayer6.norm1': 3512320, 'features.denseblock4.denselayer2.conv1': 3411968, 'features.denseblock4.denselayer1.conv1': 3211264, 'features.denseblock1.denselayer5.norm1': 3010560, 'features.denseblock1.denselayer4.norm1': 2508800, 'features.denseblock1.denselayer1.norm2': 2007040, 'features.denseblock1.denselayer2.norm2': 2007040, 'features.denseblock1.denselayer3.norm1': 2007040, 'features.denseblock1.denselayer3.norm2': 2007040, 'features.denseblock1.denselayer4.norm2': 2007040, 'features.denseblock1.denselayer5.norm2': 2007040, 'features.denseblock1.denselayer6.norm2': 2007040, 'features.transition2.norm': 2007040, 'features.denseblock2.denselayer12.norm1': 1881600, 'features.denseblock4.denselayer1.conv2': 1806336, 'features.denseblock4.denselayer2.conv2': 1806336, 'features.denseblock4.denselayer3.conv2': 1806336, 'features.denseblock4.denselayer4.conv2': 1806336, 'features.denseblock4.denselayer5.conv2': 1806336, 'features.denseblock4.denselayer6.conv2': 1806336, 'features.denseblock4.denselayer7.conv2': 1806336, 'features.denseblock4.denselayer8.conv2': 1806336, 'features.denseblock4.denselayer9.conv2': 1806336, 'features.denseblock4.denselayer10.conv2': 1806336, 'features.denseblock4.denselayer11.conv2': 1806336, 'features.denseblock4.denselayer12.conv2': 1806336, 'features.denseblock4.denselayer13.conv2': 1806336, 'features.denseblock4.denselayer14.conv2': 1806336, 'features.denseblock4.denselayer15.conv2': 1806336, 'features.denseblock4.denselayer16.conv2': 1806336, 'features.denseblock2.denselayer11.norm1': 1756160, 'features.denseblock2.denselayer10.norm1': 1630720, 'features.denseblock1.denselayer2.norm1': 1505280, 'features.denseblock2.denselayer9.norm1': 1505280, 'features.denseblock2.denselayer8.norm1': 1379840, 'features.denseblock2.denselayer7.norm1': 1254400, 'features.denseblock2.denselayer6.norm1': 1128960, 'features.denseblock1.denselayer1.norm1': 1003520, 'features.denseblock2.denselayer5.norm1': 1003520, 'features.transition3.norm': 1003520, 'features.denseblock3.denselayer24.norm1': 972160, 'features.denseblock3.denselayer23.norm1': 940800, 'features.denseblock3.denselayer22.norm1': 909440, 'features.denseblock2.denselayer4.norm1': 878080, 'features.denseblock3.denselayer21.norm1': 878080, 'features.denseblock3.denselayer20.norm1': 846720, 'features.denseblock3.denselayer19.norm1': 815360, 'features.denseblock3.denselayer18.norm1': 784000, 'features.denseblock2.denselayer3.norm1': 752640, 'features.denseblock3.denselayer17.norm1': 752640, 'features.denseblock3.denselayer16.norm1': 721280, 'features.denseblock3.denselayer15.norm1': 689920, 'features.denseblock3.denselayer14.norm1': 658560, 'features.denseblock2.denselayer2.norm1': 627200, 'features.denseblock3.denselayer13.norm1': 627200, 'features.denseblock3.denselayer12.norm1': 595840, 'features.denseblock3.denselayer11.norm1': 564480, 'features.denseblock3.denselayer10.norm1': 533120, 'features.denseblock2.denselayer1.norm1': 501760, 'features.denseblock2.denselayer1.norm2': 501760, 'features.denseblock2.denselayer2.norm2': 501760, 'features.denseblock2.denselayer3.norm2': 501760, 'features.denseblock2.denselayer4.norm2': 501760, 'features.denseblock2.denselayer5.norm2': 501760, 'features.denseblock2.denselayer6.norm2': 501760, 'features.denseblock2.denselayer7.norm2': 501760, 'features.denseblock2.denselayer8.norm2': 501760, 'features.denseblock2.denselayer9.norm2': 501760, 'features.denseblock2.denselayer10.norm2': 501760, 'features.denseblock2.denselayer11.norm2': 501760, 'features.denseblock2.denselayer12.norm2': 501760, 'features.denseblock3.denselayer9.norm1': 501760, 'features.denseblock3.denselayer8.norm1': 470400, 'features.denseblock3.denselayer7.norm1': 439040, 'features.denseblock3.denselayer6.norm1': 407680, 'features.denseblock3.denselayer5.norm1': 376320, 'features.denseblock3.denselayer4.norm1': 344960, 'features.denseblock3.denselayer3.norm1': 313600, 'features.denseblock3.denselayer2.norm1': 282240, 'features.denseblock3.denselayer1.norm1': 250880, 'features.norm5': 250880, 'features.denseblock4.denselayer16.norm1': 243040, 'features.denseblock4.denselayer15.norm1': 235200, 'features.denseblock4.denselayer14.norm1': 227360, 'features.denseblock4.denselayer13.norm1': 219520, 'features.denseblock4.denselayer12.norm1': 211680, 'features.denseblock4.denselayer11.norm1': 203840, 'features.denseblock4.denselayer10.norm1': 196000, 'features.denseblock4.denselayer9.norm1': 188160, 'features.denseblock4.denselayer8.norm1': 180320, 'features.denseblock4.denselayer7.norm1': 172480, 'features.denseblock4.denselayer6.norm1': 164640, 'features.denseblock4.denselayer5.norm1': 156800, 'features.denseblock4.denselayer4.norm1': 148960, 'features.denseblock4.denselayer3.norm1': 141120, 'features.denseblock4.denselayer2.norm1': 133280, 'features.denseblock3.denselayer1.norm2': 125440, 'features.denseblock3.denselayer2.norm2': 125440, 'features.denseblock3.denselayer3.norm2': 125440, 'features.denseblock3.denselayer4.norm2': 125440, 'features.denseblock3.denselayer5.norm2': 125440, 'features.denseblock3.denselayer6.norm2': 125440, 'features.denseblock3.denselayer7.norm2': 125440, 'features.denseblock3.denselayer8.norm2': 125440, 'features.denseblock3.denselayer9.norm2': 125440, 'features.denseblock3.denselayer10.norm2': 125440, 'features.denseblock3.denselayer11.norm2': 125440, 'features.denseblock3.denselayer12.norm2': 125440, 'features.denseblock3.denselayer13.norm2': 125440, 'features.denseblock3.denselayer14.norm2': 125440, 'features.denseblock3.denselayer15.norm2': 125440, 'features.denseblock3.denselayer16.norm2': 125440, 'features.denseblock3.denselayer17.norm2': 125440, 'features.denseblock3.denselayer18.norm2': 125440, 'features.denseblock3.denselayer19.norm2': 125440, 'features.denseblock3.denselayer20.norm2': 125440, 'features.denseblock3.denselayer21.norm2': 125440, 'features.denseblock3.denselayer22.norm2': 125440, 'features.denseblock3.denselayer23.norm2': 125440, 'features.denseblock3.denselayer24.norm2': 125440, 'features.denseblock4.denselayer1.norm1': 125440, 'features.denseblock4.denselayer1.norm2': 31360, 'features.denseblock4.denselayer2.norm2': 31360, 'features.denseblock4.denselayer3.norm2': 31360, 'features.denseblock4.denselayer4.norm2': 31360, 'features.denseblock4.denselayer5.norm2': 31360, 'features.denseblock4.denselayer6.norm2': 31360, 'features.denseblock4.denselayer7.norm2': 31360, 'features.denseblock4.denselayer8.norm2': 31360, 'features.denseblock4.denselayer9.norm2': 31360, 'features.denseblock4.denselayer10.norm2': 31360, 'features.denseblock4.denselayer11.norm2': 31360, 'features.denseblock4.denselayer12.norm2': 31360, 'features.denseblock4.denselayer13.norm2': 31360, 'features.denseblock4.denselayer14.norm2': 31360, 'features.denseblock4.denselayer15.norm2': 31360, 'features.denseblock4.denselayer16.norm2': 31360, 'classifier': 4096, 'features.relu0': 0, 'features.pool0': 0, 'features.denseblock1.denselayer1.relu1': 0, 'features.denseblock1.denselayer1.relu2': 0, 'features.denseblock1.denselayer2.relu1': 0, 'features.denseblock1.denselayer2.relu2': 0, 'features.denseblock1.denselayer3.relu1': 0, 'features.denseblock1.denselayer3.relu2': 0, 'features.denseblock1.denselayer4.relu1': 0, 'features.denseblock1.denselayer4.relu2': 0, 'features.denseblock1.denselayer5.relu1': 0, 'features.denseblock1.denselayer5.relu2': 0, 'features.denseblock1.denselayer6.relu1': 0, 'features.denseblock1.denselayer6.relu2': 0, 'features.transition1.relu': 0, 'features.transition1.pool': 0, 'features.denseblock2.denselayer1.relu1': 0, 'features.denseblock2.denselayer1.relu2': 0, 'features.denseblock2.denselayer2.relu1': 0, 'features.denseblock2.denselayer2.relu2': 0, 'features.denseblock2.denselayer3.relu1': 0, 'features.denseblock2.denselayer3.relu2': 0, 'features.denseblock2.denselayer4.relu1': 0, 'features.denseblock2.denselayer4.relu2': 0, 'features.denseblock2.denselayer5.relu1': 0, 'features.denseblock2.denselayer5.relu2': 0, 'features.denseblock2.denselayer6.relu1': 0, 'features.denseblock2.denselayer6.relu2': 0, 'features.denseblock2.denselayer7.relu1': 0, 'features.denseblock2.denselayer7.relu2': 0, 'features.denseblock2.denselayer8.relu1': 0, 'features.denseblock2.denselayer8.relu2': 0, 'features.denseblock2.denselayer9.relu1': 0, 'features.denseblock2.denselayer9.relu2': 0, 'features.denseblock2.denselayer10.relu1': 0, 'features.denseblock2.denselayer10.relu2': 0, 'features.denseblock2.denselayer11.relu1': 0, 'features.denseblock2.denselayer11.relu2': 0, 'features.denseblock2.denselayer12.relu1': 0, 'features.denseblock2.denselayer12.relu2': 0, 'features.transition2.relu': 0, 'features.transition2.pool': 0, 'features.denseblock3.denselayer1.relu1': 0, 'features.denseblock3.denselayer1.relu2': 0, 'features.denseblock3.denselayer2.relu1': 0, 'features.denseblock3.denselayer2.relu2': 0, 'features.denseblock3.denselayer3.relu1': 0, 'features.denseblock3.denselayer3.relu2': 0, 'features.denseblock3.denselayer4.relu1': 0, 'features.denseblock3.denselayer4.relu2': 0, 'features.denseblock3.denselayer5.relu1': 0, 'features.denseblock3.denselayer5.relu2': 0, 'features.denseblock3.denselayer6.relu1': 0, 'features.denseblock3.denselayer6.relu2': 0, 'features.denseblock3.denselayer7.relu1': 0, 'features.denseblock3.denselayer7.relu2': 0, 'features.denseblock3.denselayer8.relu1': 0, 'features.denseblock3.denselayer8.relu2': 0, 'features.denseblock3.denselayer9.relu1': 0, 'features.denseblock3.denselayer9.relu2': 0, 'features.denseblock3.denselayer10.relu1': 0, 'features.denseblock3.denselayer10.relu2': 0, 'features.denseblock3.denselayer11.relu1': 0, 'features.denseblock3.denselayer11.relu2': 0, 'features.denseblock3.denselayer12.relu1': 0, 'features.denseblock3.denselayer12.relu2': 0, 'features.denseblock3.denselayer13.relu1': 0, 'features.denseblock3.denselayer13.relu2': 0, 'features.denseblock3.denselayer14.relu1': 0, 'features.denseblock3.denselayer14.relu2': 0, 'features.denseblock3.denselayer15.relu1': 0, 'features.denseblock3.denselayer15.relu2': 0, 'features.denseblock3.denselayer16.relu1': 0, 'features.denseblock3.denselayer16.relu2': 0, 'features.denseblock3.denselayer17.relu1': 0, 'features.denseblock3.denselayer17.relu2': 0, 'features.denseblock3.denselayer18.relu1': 0, 'features.denseblock3.denselayer18.relu2': 0, 'features.denseblock3.denselayer19.relu1': 0, 'features.denseblock3.denselayer19.relu2': 0, 'features.denseblock3.denselayer20.relu1': 0, 'features.denseblock3.denselayer20.relu2': 0, 'features.denseblock3.denselayer21.relu1': 0, 'features.denseblock3.denselayer21.relu2': 0, 'features.denseblock3.denselayer22.relu1': 0, 'features.denseblock3.denselayer22.relu2': 0, 'features.denseblock3.denselayer23.relu1': 0, 'features.denseblock3.denselayer23.relu2': 0, 'features.denseblock3.denselayer24.relu1': 0, 'features.denseblock3.denselayer24.relu2': 0, 'features.transition3.relu': 0, 'features.transition3.pool': 0, 'features.denseblock4.denselayer1.relu1': 0, 'features.denseblock4.denselayer1.relu2': 0, 'features.denseblock4.denselayer2.relu1': 0, 'features.denseblock4.denselayer2.relu2': 0, 'features.denseblock4.denselayer3.relu1': 0, 'features.denseblock4.denselayer3.relu2': 0, 'features.denseblock4.denselayer4.relu1': 0, 'features.denseblock4.denselayer4.relu2': 0, 'features.denseblock4.denselayer5.relu1': 0, 'features.denseblock4.denselayer5.relu2': 0, 'features.denseblock4.denselayer6.relu1': 0, 'features.denseblock4.denselayer6.relu2': 0, 'features.denseblock4.denselayer7.relu1': 0, 'features.denseblock4.denselayer7.relu2': 0, 'features.denseblock4.denselayer8.relu1': 0, 'features.denseblock4.denselayer8.relu2': 0, 'features.denseblock4.denselayer9.relu1': 0, 'features.denseblock4.denselayer9.relu2': 0, 'features.denseblock4.denselayer10.relu1': 0, 'features.denseblock4.denselayer10.relu2': 0, 'features.denseblock4.denselayer11.relu1': 0, 'features.denseblock4.denselayer11.relu2': 0, 'features.denseblock4.denselayer12.relu1': 0, 'features.denseblock4.denselayer12.relu2': 0, 'features.denseblock4.denselayer13.relu1': 0, 'features.denseblock4.denselayer13.relu2': 0, 'features.denseblock4.denselayer14.relu1': 0, 'features.denseblock4.denselayer14.relu2': 0, 'features.denseblock4.denselayer15.relu1': 0, 'features.denseblock4.denselayer15.relu2': 0, 'features.denseblock4.denselayer16.relu1': 0, 'features.denseblock4.denselayer16.relu2': 0})\n",
            "FLOPs by module and operator for DenseNet121: {'': Counter({'conv': 2833137664, 'batch_norm': 78337280, 'adaptive_avg_pool2d': 50176, 'linear': 4096}), 'features': Counter({'conv': 2833137664, 'batch_norm': 78337280}), 'features.conv0': Counter({'conv': 118013952}), 'features.norm0': Counter({'batch_norm': 4014080}), 'features.relu0': Counter(), 'features.pool0': Counter(), 'features.denseblock1': Counter({'conv': 1040449536, 'batch_norm': 25589760}), 'features.denseblock1.denselayer1': Counter({'conv': 141295616, 'batch_norm': 3010560}), 'features.denseblock1.denselayer1.norm1': Counter({'batch_norm': 1003520}), 'features.denseblock1.denselayer1.relu1': Counter(), 'features.denseblock1.denselayer1.conv1': Counter({'conv': 25690112}), 'features.denseblock1.denselayer1.norm2': Counter({'batch_norm': 2007040}), 'features.denseblock1.denselayer1.relu2': Counter(), 'features.denseblock1.denselayer1.conv2': Counter({'conv': 115605504}), 'features.denseblock1.denselayer2': Counter({'conv': 154140672, 'batch_norm': 3512320}), 'features.denseblock1.denselayer2.norm1': Counter({'batch_norm': 1505280}), 'features.denseblock1.denselayer2.relu1': Counter(), 'features.denseblock1.denselayer2.conv1': Counter({'conv': 38535168}), 'features.denseblock1.denselayer2.norm2': Counter({'batch_norm': 2007040}), 'features.denseblock1.denselayer2.relu2': Counter(), 'features.denseblock1.denselayer2.conv2': Counter({'conv': 115605504}), 'features.denseblock1.denselayer3': Counter({'conv': 166985728, 'batch_norm': 4014080}), 'features.denseblock1.denselayer3.norm1': Counter({'batch_norm': 2007040}), 'features.denseblock1.denselayer3.relu1': Counter(), 'features.denseblock1.denselayer3.conv1': Counter({'conv': 51380224}), 'features.denseblock1.denselayer3.norm2': Counter({'batch_norm': 2007040}), 'features.denseblock1.denselayer3.relu2': Counter(), 'features.denseblock1.denselayer3.conv2': Counter({'conv': 115605504}), 'features.denseblock1.denselayer4': Counter({'conv': 179830784, 'batch_norm': 4515840}), 'features.denseblock1.denselayer4.norm1': Counter({'batch_norm': 2508800}), 'features.denseblock1.denselayer4.relu1': Counter(), 'features.denseblock1.denselayer4.conv1': Counter({'conv': 64225280}), 'features.denseblock1.denselayer4.norm2': Counter({'batch_norm': 2007040}), 'features.denseblock1.denselayer4.relu2': Counter(), 'features.denseblock1.denselayer4.conv2': Counter({'conv': 115605504}), 'features.denseblock1.denselayer5': Counter({'conv': 192675840, 'batch_norm': 5017600}), 'features.denseblock1.denselayer5.norm1': Counter({'batch_norm': 3010560}), 'features.denseblock1.denselayer5.relu1': Counter(), 'features.denseblock1.denselayer5.conv1': Counter({'conv': 77070336}), 'features.denseblock1.denselayer5.norm2': Counter({'batch_norm': 2007040}), 'features.denseblock1.denselayer5.relu2': Counter(), 'features.denseblock1.denselayer5.conv2': Counter({'conv': 115605504}), 'features.denseblock1.denselayer6': Counter({'conv': 205520896, 'batch_norm': 5519360}), 'features.denseblock1.denselayer6.norm1': Counter({'batch_norm': 3512320}), 'features.denseblock1.denselayer6.relu1': Counter(), 'features.denseblock1.denselayer6.conv1': Counter({'conv': 89915392}), 'features.denseblock1.denselayer6.norm2': Counter({'batch_norm': 2007040}), 'features.denseblock1.denselayer6.relu2': Counter(), 'features.denseblock1.denselayer6.conv2': Counter({'conv': 115605504}), 'features.transition1': Counter({'conv': 102760448, 'batch_norm': 4014080}), 'features.transition1.norm': Counter({'batch_norm': 4014080}), 'features.transition1.relu': Counter(), 'features.transition1.conv': Counter({'conv': 102760448}), 'features.transition1.pool': Counter(), 'features.denseblock2': Counter({'conv': 712900608, 'batch_norm': 20321280}), 'features.denseblock2.denselayer1': Counter({'conv': 41746432, 'batch_norm': 1003520}), 'features.denseblock2.denselayer1.norm1': Counter({'batch_norm': 501760}), 'features.denseblock2.denselayer1.relu1': Counter(), 'features.denseblock2.denselayer1.conv1': Counter({'conv': 12845056}), 'features.denseblock2.denselayer1.norm2': Counter({'batch_norm': 501760}), 'features.denseblock2.denselayer1.relu2': Counter(), 'features.denseblock2.denselayer1.conv2': Counter({'conv': 28901376}), 'features.denseblock2.denselayer2': Counter({'conv': 44957696, 'batch_norm': 1128960}), 'features.denseblock2.denselayer2.norm1': Counter({'batch_norm': 627200}), 'features.denseblock2.denselayer2.relu1': Counter(), 'features.denseblock2.denselayer2.conv1': Counter({'conv': 16056320}), 'features.denseblock2.denselayer2.norm2': Counter({'batch_norm': 501760}), 'features.denseblock2.denselayer2.relu2': Counter(), 'features.denseblock2.denselayer2.conv2': Counter({'conv': 28901376}), 'features.denseblock2.denselayer3': Counter({'conv': 48168960, 'batch_norm': 1254400}), 'features.denseblock2.denselayer3.norm1': Counter({'batch_norm': 752640}), 'features.denseblock2.denselayer3.relu1': Counter(), 'features.denseblock2.denselayer3.conv1': Counter({'conv': 19267584}), 'features.denseblock2.denselayer3.norm2': Counter({'batch_norm': 501760}), 'features.denseblock2.denselayer3.relu2': Counter(), 'features.denseblock2.denselayer3.conv2': Counter({'conv': 28901376}), 'features.denseblock2.denselayer4': Counter({'conv': 51380224, 'batch_norm': 1379840}), 'features.denseblock2.denselayer4.norm1': Counter({'batch_norm': 878080}), 'features.denseblock2.denselayer4.relu1': Counter(), 'features.denseblock2.denselayer4.conv1': Counter({'conv': 22478848}), 'features.denseblock2.denselayer4.norm2': Counter({'batch_norm': 501760}), 'features.denseblock2.denselayer4.relu2': Counter(), 'features.denseblock2.denselayer4.conv2': Counter({'conv': 28901376}), 'features.denseblock2.denselayer5': Counter({'conv': 54591488, 'batch_norm': 1505280}), 'features.denseblock2.denselayer5.norm1': Counter({'batch_norm': 1003520}), 'features.denseblock2.denselayer5.relu1': Counter(), 'features.denseblock2.denselayer5.conv1': Counter({'conv': 25690112}), 'features.denseblock2.denselayer5.norm2': Counter({'batch_norm': 501760}), 'features.denseblock2.denselayer5.relu2': Counter(), 'features.denseblock2.denselayer5.conv2': Counter({'conv': 28901376}), 'features.denseblock2.denselayer6': Counter({'conv': 57802752, 'batch_norm': 1630720}), 'features.denseblock2.denselayer6.norm1': Counter({'batch_norm': 1128960}), 'features.denseblock2.denselayer6.relu1': Counter(), 'features.denseblock2.denselayer6.conv1': Counter({'conv': 28901376}), 'features.denseblock2.denselayer6.norm2': Counter({'batch_norm': 501760}), 'features.denseblock2.denselayer6.relu2': Counter(), 'features.denseblock2.denselayer6.conv2': Counter({'conv': 28901376}), 'features.denseblock2.denselayer7': Counter({'conv': 61014016, 'batch_norm': 1756160}), 'features.denseblock2.denselayer7.norm1': Counter({'batch_norm': 1254400}), 'features.denseblock2.denselayer7.relu1': Counter(), 'features.denseblock2.denselayer7.conv1': Counter({'conv': 32112640}), 'features.denseblock2.denselayer7.norm2': Counter({'batch_norm': 501760}), 'features.denseblock2.denselayer7.relu2': Counter(), 'features.denseblock2.denselayer7.conv2': Counter({'conv': 28901376}), 'features.denseblock2.denselayer8': Counter({'conv': 64225280, 'batch_norm': 1881600}), 'features.denseblock2.denselayer8.norm1': Counter({'batch_norm': 1379840}), 'features.denseblock2.denselayer8.relu1': Counter(), 'features.denseblock2.denselayer8.conv1': Counter({'conv': 35323904}), 'features.denseblock2.denselayer8.norm2': Counter({'batch_norm': 501760}), 'features.denseblock2.denselayer8.relu2': Counter(), 'features.denseblock2.denselayer8.conv2': Counter({'conv': 28901376}), 'features.denseblock2.denselayer9': Counter({'conv': 67436544, 'batch_norm': 2007040}), 'features.denseblock2.denselayer9.norm1': Counter({'batch_norm': 1505280}), 'features.denseblock2.denselayer9.relu1': Counter(), 'features.denseblock2.denselayer9.conv1': Counter({'conv': 38535168}), 'features.denseblock2.denselayer9.norm2': Counter({'batch_norm': 501760}), 'features.denseblock2.denselayer9.relu2': Counter(), 'features.denseblock2.denselayer9.conv2': Counter({'conv': 28901376}), 'features.denseblock2.denselayer10': Counter({'conv': 70647808, 'batch_norm': 2132480}), 'features.denseblock2.denselayer10.norm1': Counter({'batch_norm': 1630720}), 'features.denseblock2.denselayer10.relu1': Counter(), 'features.denseblock2.denselayer10.conv1': Counter({'conv': 41746432}), 'features.denseblock2.denselayer10.norm2': Counter({'batch_norm': 501760}), 'features.denseblock2.denselayer10.relu2': Counter(), 'features.denseblock2.denselayer10.conv2': Counter({'conv': 28901376}), 'features.denseblock2.denselayer11': Counter({'conv': 73859072, 'batch_norm': 2257920}), 'features.denseblock2.denselayer11.norm1': Counter({'batch_norm': 1756160}), 'features.denseblock2.denselayer11.relu1': Counter(), 'features.denseblock2.denselayer11.conv1': Counter({'conv': 44957696}), 'features.denseblock2.denselayer11.norm2': Counter({'batch_norm': 501760}), 'features.denseblock2.denselayer11.relu2': Counter(), 'features.denseblock2.denselayer11.conv2': Counter({'conv': 28901376}), 'features.denseblock2.denselayer12': Counter({'conv': 77070336, 'batch_norm': 2383360}), 'features.denseblock2.denselayer12.norm1': Counter({'batch_norm': 1881600}), 'features.denseblock2.denselayer12.relu1': Counter(), 'features.denseblock2.denselayer12.conv1': Counter({'conv': 48168960}), 'features.denseblock2.denselayer12.norm2': Counter({'batch_norm': 501760}), 'features.denseblock2.denselayer12.relu2': Counter(), 'features.denseblock2.denselayer12.conv2': Counter({'conv': 28901376}), 'features.transition2': Counter({'conv': 102760448, 'batch_norm': 2007040}), 'features.transition2.norm': Counter({'batch_norm': 2007040}), 'features.transition2.relu': Counter(), 'features.transition2.conv': Counter({'conv': 102760448}), 'features.transition2.pool': Counter(), 'features.denseblock3': Counter({'conv': 549126144, 'batch_norm': 17687040}), 'features.denseblock3.denselayer1': Counter({'conv': 13647872, 'batch_norm': 376320}), 'features.denseblock3.denselayer1.norm1': Counter({'batch_norm': 250880}), 'features.denseblock3.denselayer1.relu1': Counter(), 'features.denseblock3.denselayer1.conv1': Counter({'conv': 6422528}), 'features.denseblock3.denselayer1.norm2': Counter({'batch_norm': 125440}), 'features.denseblock3.denselayer1.relu2': Counter(), 'features.denseblock3.denselayer1.conv2': Counter({'conv': 7225344}), 'features.denseblock3.denselayer2': Counter({'conv': 14450688, 'batch_norm': 407680}), 'features.denseblock3.denselayer2.norm1': Counter({'batch_norm': 282240}), 'features.denseblock3.denselayer2.relu1': Counter(), 'features.denseblock3.denselayer2.conv1': Counter({'conv': 7225344}), 'features.denseblock3.denselayer2.norm2': Counter({'batch_norm': 125440}), 'features.denseblock3.denselayer2.relu2': Counter(), 'features.denseblock3.denselayer2.conv2': Counter({'conv': 7225344}), 'features.denseblock3.denselayer3': Counter({'conv': 15253504, 'batch_norm': 439040}), 'features.denseblock3.denselayer3.norm1': Counter({'batch_norm': 313600}), 'features.denseblock3.denselayer3.relu1': Counter(), 'features.denseblock3.denselayer3.conv1': Counter({'conv': 8028160}), 'features.denseblock3.denselayer3.norm2': Counter({'batch_norm': 125440}), 'features.denseblock3.denselayer3.relu2': Counter(), 'features.denseblock3.denselayer3.conv2': Counter({'conv': 7225344}), 'features.denseblock3.denselayer4': Counter({'conv': 16056320, 'batch_norm': 470400}), 'features.denseblock3.denselayer4.norm1': Counter({'batch_norm': 344960}), 'features.denseblock3.denselayer4.relu1': Counter(), 'features.denseblock3.denselayer4.conv1': Counter({'conv': 8830976}), 'features.denseblock3.denselayer4.norm2': Counter({'batch_norm': 125440}), 'features.denseblock3.denselayer4.relu2': Counter(), 'features.denseblock3.denselayer4.conv2': Counter({'conv': 7225344}), 'features.denseblock3.denselayer5': Counter({'conv': 16859136, 'batch_norm': 501760}), 'features.denseblock3.denselayer5.norm1': Counter({'batch_norm': 376320}), 'features.denseblock3.denselayer5.relu1': Counter(), 'features.denseblock3.denselayer5.conv1': Counter({'conv': 9633792}), 'features.denseblock3.denselayer5.norm2': Counter({'batch_norm': 125440}), 'features.denseblock3.denselayer5.relu2': Counter(), 'features.denseblock3.denselayer5.conv2': Counter({'conv': 7225344}), 'features.denseblock3.denselayer6': Counter({'conv': 17661952, 'batch_norm': 533120}), 'features.denseblock3.denselayer6.norm1': Counter({'batch_norm': 407680}), 'features.denseblock3.denselayer6.relu1': Counter(), 'features.denseblock3.denselayer6.conv1': Counter({'conv': 10436608}), 'features.denseblock3.denselayer6.norm2': Counter({'batch_norm': 125440}), 'features.denseblock3.denselayer6.relu2': Counter(), 'features.denseblock3.denselayer6.conv2': Counter({'conv': 7225344}), 'features.denseblock3.denselayer7': Counter({'conv': 18464768, 'batch_norm': 564480}), 'features.denseblock3.denselayer7.norm1': Counter({'batch_norm': 439040}), 'features.denseblock3.denselayer7.relu1': Counter(), 'features.denseblock3.denselayer7.conv1': Counter({'conv': 11239424}), 'features.denseblock3.denselayer7.norm2': Counter({'batch_norm': 125440}), 'features.denseblock3.denselayer7.relu2': Counter(), 'features.denseblock3.denselayer7.conv2': Counter({'conv': 7225344}), 'features.denseblock3.denselayer8': Counter({'conv': 19267584, 'batch_norm': 595840}), 'features.denseblock3.denselayer8.norm1': Counter({'batch_norm': 470400}), 'features.denseblock3.denselayer8.relu1': Counter(), 'features.denseblock3.denselayer8.conv1': Counter({'conv': 12042240}), 'features.denseblock3.denselayer8.norm2': Counter({'batch_norm': 125440}), 'features.denseblock3.denselayer8.relu2': Counter(), 'features.denseblock3.denselayer8.conv2': Counter({'conv': 7225344}), 'features.denseblock3.denselayer9': Counter({'conv': 20070400, 'batch_norm': 627200}), 'features.denseblock3.denselayer9.norm1': Counter({'batch_norm': 501760}), 'features.denseblock3.denselayer9.relu1': Counter(), 'features.denseblock3.denselayer9.conv1': Counter({'conv': 12845056}), 'features.denseblock3.denselayer9.norm2': Counter({'batch_norm': 125440}), 'features.denseblock3.denselayer9.relu2': Counter(), 'features.denseblock3.denselayer9.conv2': Counter({'conv': 7225344}), 'features.denseblock3.denselayer10': Counter({'conv': 20873216, 'batch_norm': 658560}), 'features.denseblock3.denselayer10.norm1': Counter({'batch_norm': 533120}), 'features.denseblock3.denselayer10.relu1': Counter(), 'features.denseblock3.denselayer10.conv1': Counter({'conv': 13647872}), 'features.denseblock3.denselayer10.norm2': Counter({'batch_norm': 125440}), 'features.denseblock3.denselayer10.relu2': Counter(), 'features.denseblock3.denselayer10.conv2': Counter({'conv': 7225344}), 'features.denseblock3.denselayer11': Counter({'conv': 21676032, 'batch_norm': 689920}), 'features.denseblock3.denselayer11.norm1': Counter({'batch_norm': 564480}), 'features.denseblock3.denselayer11.relu1': Counter(), 'features.denseblock3.denselayer11.conv1': Counter({'conv': 14450688}), 'features.denseblock3.denselayer11.norm2': Counter({'batch_norm': 125440}), 'features.denseblock3.denselayer11.relu2': Counter(), 'features.denseblock3.denselayer11.conv2': Counter({'conv': 7225344}), 'features.denseblock3.denselayer12': Counter({'conv': 22478848, 'batch_norm': 721280}), 'features.denseblock3.denselayer12.norm1': Counter({'batch_norm': 595840}), 'features.denseblock3.denselayer12.relu1': Counter(), 'features.denseblock3.denselayer12.conv1': Counter({'conv': 15253504}), 'features.denseblock3.denselayer12.norm2': Counter({'batch_norm': 125440}), 'features.denseblock3.denselayer12.relu2': Counter(), 'features.denseblock3.denselayer12.conv2': Counter({'conv': 7225344}), 'features.denseblock3.denselayer13': Counter({'conv': 23281664, 'batch_norm': 752640}), 'features.denseblock3.denselayer13.norm1': Counter({'batch_norm': 627200}), 'features.denseblock3.denselayer13.relu1': Counter(), 'features.denseblock3.denselayer13.conv1': Counter({'conv': 16056320}), 'features.denseblock3.denselayer13.norm2': Counter({'batch_norm': 125440}), 'features.denseblock3.denselayer13.relu2': Counter(), 'features.denseblock3.denselayer13.conv2': Counter({'conv': 7225344}), 'features.denseblock3.denselayer14': Counter({'conv': 24084480, 'batch_norm': 784000}), 'features.denseblock3.denselayer14.norm1': Counter({'batch_norm': 658560}), 'features.denseblock3.denselayer14.relu1': Counter(), 'features.denseblock3.denselayer14.conv1': Counter({'conv': 16859136}), 'features.denseblock3.denselayer14.norm2': Counter({'batch_norm': 125440}), 'features.denseblock3.denselayer14.relu2': Counter(), 'features.denseblock3.denselayer14.conv2': Counter({'conv': 7225344}), 'features.denseblock3.denselayer15': Counter({'conv': 24887296, 'batch_norm': 815360}), 'features.denseblock3.denselayer15.norm1': Counter({'batch_norm': 689920}), 'features.denseblock3.denselayer15.relu1': Counter(), 'features.denseblock3.denselayer15.conv1': Counter({'conv': 17661952}), 'features.denseblock3.denselayer15.norm2': Counter({'batch_norm': 125440}), 'features.denseblock3.denselayer15.relu2': Counter(), 'features.denseblock3.denselayer15.conv2': Counter({'conv': 7225344}), 'features.denseblock3.denselayer16': Counter({'conv': 25690112, 'batch_norm': 846720}), 'features.denseblock3.denselayer16.norm1': Counter({'batch_norm': 721280}), 'features.denseblock3.denselayer16.relu1': Counter(), 'features.denseblock3.denselayer16.conv1': Counter({'conv': 18464768}), 'features.denseblock3.denselayer16.norm2': Counter({'batch_norm': 125440}), 'features.denseblock3.denselayer16.relu2': Counter(), 'features.denseblock3.denselayer16.conv2': Counter({'conv': 7225344}), 'features.denseblock3.denselayer17': Counter({'conv': 26492928, 'batch_norm': 878080}), 'features.denseblock3.denselayer17.norm1': Counter({'batch_norm': 752640}), 'features.denseblock3.denselayer17.relu1': Counter(), 'features.denseblock3.denselayer17.conv1': Counter({'conv': 19267584}), 'features.denseblock3.denselayer17.norm2': Counter({'batch_norm': 125440}), 'features.denseblock3.denselayer17.relu2': Counter(), 'features.denseblock3.denselayer17.conv2': Counter({'conv': 7225344}), 'features.denseblock3.denselayer18': Counter({'conv': 27295744, 'batch_norm': 909440}), 'features.denseblock3.denselayer18.norm1': Counter({'batch_norm': 784000}), 'features.denseblock3.denselayer18.relu1': Counter(), 'features.denseblock3.denselayer18.conv1': Counter({'conv': 20070400}), 'features.denseblock3.denselayer18.norm2': Counter({'batch_norm': 125440}), 'features.denseblock3.denselayer18.relu2': Counter(), 'features.denseblock3.denselayer18.conv2': Counter({'conv': 7225344}), 'features.denseblock3.denselayer19': Counter({'conv': 28098560, 'batch_norm': 940800}), 'features.denseblock3.denselayer19.norm1': Counter({'batch_norm': 815360}), 'features.denseblock3.denselayer19.relu1': Counter(), 'features.denseblock3.denselayer19.conv1': Counter({'conv': 20873216}), 'features.denseblock3.denselayer19.norm2': Counter({'batch_norm': 125440}), 'features.denseblock3.denselayer19.relu2': Counter(), 'features.denseblock3.denselayer19.conv2': Counter({'conv': 7225344}), 'features.denseblock3.denselayer20': Counter({'conv': 28901376, 'batch_norm': 972160}), 'features.denseblock3.denselayer20.norm1': Counter({'batch_norm': 846720}), 'features.denseblock3.denselayer20.relu1': Counter(), 'features.denseblock3.denselayer20.conv1': Counter({'conv': 21676032}), 'features.denseblock3.denselayer20.norm2': Counter({'batch_norm': 125440}), 'features.denseblock3.denselayer20.relu2': Counter(), 'features.denseblock3.denselayer20.conv2': Counter({'conv': 7225344}), 'features.denseblock3.denselayer21': Counter({'conv': 29704192, 'batch_norm': 1003520}), 'features.denseblock3.denselayer21.norm1': Counter({'batch_norm': 878080}), 'features.denseblock3.denselayer21.relu1': Counter(), 'features.denseblock3.denselayer21.conv1': Counter({'conv': 22478848}), 'features.denseblock3.denselayer21.norm2': Counter({'batch_norm': 125440}), 'features.denseblock3.denselayer21.relu2': Counter(), 'features.denseblock3.denselayer21.conv2': Counter({'conv': 7225344}), 'features.denseblock3.denselayer22': Counter({'conv': 30507008, 'batch_norm': 1034880}), 'features.denseblock3.denselayer22.norm1': Counter({'batch_norm': 909440}), 'features.denseblock3.denselayer22.relu1': Counter(), 'features.denseblock3.denselayer22.conv1': Counter({'conv': 23281664}), 'features.denseblock3.denselayer22.norm2': Counter({'batch_norm': 125440}), 'features.denseblock3.denselayer22.relu2': Counter(), 'features.denseblock3.denselayer22.conv2': Counter({'conv': 7225344}), 'features.denseblock3.denselayer23': Counter({'conv': 31309824, 'batch_norm': 1066240}), 'features.denseblock3.denselayer23.norm1': Counter({'batch_norm': 940800}), 'features.denseblock3.denselayer23.relu1': Counter(), 'features.denseblock3.denselayer23.conv1': Counter({'conv': 24084480}), 'features.denseblock3.denselayer23.norm2': Counter({'batch_norm': 125440}), 'features.denseblock3.denselayer23.relu2': Counter(), 'features.denseblock3.denselayer23.conv2': Counter({'conv': 7225344}), 'features.denseblock3.denselayer24': Counter({'conv': 32112640, 'batch_norm': 1097600}), 'features.denseblock3.denselayer24.norm1': Counter({'batch_norm': 972160}), 'features.denseblock3.denselayer24.relu1': Counter(), 'features.denseblock3.denselayer24.conv1': Counter({'conv': 24887296}), 'features.denseblock3.denselayer24.norm2': Counter({'batch_norm': 125440}), 'features.denseblock3.denselayer24.relu2': Counter(), 'features.denseblock3.denselayer24.conv2': Counter({'conv': 7225344}), 'features.transition3': Counter({'conv': 102760448, 'batch_norm': 1003520}), 'features.transition3.norm': Counter({'batch_norm': 1003520}), 'features.transition3.relu': Counter(), 'features.transition3.conv': Counter({'conv': 102760448}), 'features.transition3.pool': Counter(), 'features.denseblock4': Counter({'conv': 104366080, 'batch_norm': 3449600}), 'features.denseblock4.denselayer1': Counter({'conv': 5017600, 'batch_norm': 156800}), 'features.denseblock4.denselayer1.norm1': Counter({'batch_norm': 125440}), 'features.denseblock4.denselayer1.relu1': Counter(), 'features.denseblock4.denselayer1.conv1': Counter({'conv': 3211264}), 'features.denseblock4.denselayer1.norm2': Counter({'batch_norm': 31360}), 'features.denseblock4.denselayer1.relu2': Counter(), 'features.denseblock4.denselayer1.conv2': Counter({'conv': 1806336}), 'features.denseblock4.denselayer2': Counter({'conv': 5218304, 'batch_norm': 164640}), 'features.denseblock4.denselayer2.norm1': Counter({'batch_norm': 133280}), 'features.denseblock4.denselayer2.relu1': Counter(), 'features.denseblock4.denselayer2.conv1': Counter({'conv': 3411968}), 'features.denseblock4.denselayer2.norm2': Counter({'batch_norm': 31360}), 'features.denseblock4.denselayer2.relu2': Counter(), 'features.denseblock4.denselayer2.conv2': Counter({'conv': 1806336}), 'features.denseblock4.denselayer3': Counter({'conv': 5419008, 'batch_norm': 172480}), 'features.denseblock4.denselayer3.norm1': Counter({'batch_norm': 141120}), 'features.denseblock4.denselayer3.relu1': Counter(), 'features.denseblock4.denselayer3.conv1': Counter({'conv': 3612672}), 'features.denseblock4.denselayer3.norm2': Counter({'batch_norm': 31360}), 'features.denseblock4.denselayer3.relu2': Counter(), 'features.denseblock4.denselayer3.conv2': Counter({'conv': 1806336}), 'features.denseblock4.denselayer4': Counter({'conv': 5619712, 'batch_norm': 180320}), 'features.denseblock4.denselayer4.norm1': Counter({'batch_norm': 148960}), 'features.denseblock4.denselayer4.relu1': Counter(), 'features.denseblock4.denselayer4.conv1': Counter({'conv': 3813376}), 'features.denseblock4.denselayer4.norm2': Counter({'batch_norm': 31360}), 'features.denseblock4.denselayer4.relu2': Counter(), 'features.denseblock4.denselayer4.conv2': Counter({'conv': 1806336}), 'features.denseblock4.denselayer5': Counter({'conv': 5820416, 'batch_norm': 188160}), 'features.denseblock4.denselayer5.norm1': Counter({'batch_norm': 156800}), 'features.denseblock4.denselayer5.relu1': Counter(), 'features.denseblock4.denselayer5.conv1': Counter({'conv': 4014080}), 'features.denseblock4.denselayer5.norm2': Counter({'batch_norm': 31360}), 'features.denseblock4.denselayer5.relu2': Counter(), 'features.denseblock4.denselayer5.conv2': Counter({'conv': 1806336}), 'features.denseblock4.denselayer6': Counter({'conv': 6021120, 'batch_norm': 196000}), 'features.denseblock4.denselayer6.norm1': Counter({'batch_norm': 164640}), 'features.denseblock4.denselayer6.relu1': Counter(), 'features.denseblock4.denselayer6.conv1': Counter({'conv': 4214784}), 'features.denseblock4.denselayer6.norm2': Counter({'batch_norm': 31360}), 'features.denseblock4.denselayer6.relu2': Counter(), 'features.denseblock4.denselayer6.conv2': Counter({'conv': 1806336}), 'features.denseblock4.denselayer7': Counter({'conv': 6221824, 'batch_norm': 203840}), 'features.denseblock4.denselayer7.norm1': Counter({'batch_norm': 172480}), 'features.denseblock4.denselayer7.relu1': Counter(), 'features.denseblock4.denselayer7.conv1': Counter({'conv': 4415488}), 'features.denseblock4.denselayer7.norm2': Counter({'batch_norm': 31360}), 'features.denseblock4.denselayer7.relu2': Counter(), 'features.denseblock4.denselayer7.conv2': Counter({'conv': 1806336}), 'features.denseblock4.denselayer8': Counter({'conv': 6422528, 'batch_norm': 211680}), 'features.denseblock4.denselayer8.norm1': Counter({'batch_norm': 180320}), 'features.denseblock4.denselayer8.relu1': Counter(), 'features.denseblock4.denselayer8.conv1': Counter({'conv': 4616192}), 'features.denseblock4.denselayer8.norm2': Counter({'batch_norm': 31360}), 'features.denseblock4.denselayer8.relu2': Counter(), 'features.denseblock4.denselayer8.conv2': Counter({'conv': 1806336}), 'features.denseblock4.denselayer9': Counter({'conv': 6623232, 'batch_norm': 219520}), 'features.denseblock4.denselayer9.norm1': Counter({'batch_norm': 188160}), 'features.denseblock4.denselayer9.relu1': Counter(), 'features.denseblock4.denselayer9.conv1': Counter({'conv': 4816896}), 'features.denseblock4.denselayer9.norm2': Counter({'batch_norm': 31360}), 'features.denseblock4.denselayer9.relu2': Counter(), 'features.denseblock4.denselayer9.conv2': Counter({'conv': 1806336}), 'features.denseblock4.denselayer10': Counter({'conv': 6823936, 'batch_norm': 227360}), 'features.denseblock4.denselayer10.norm1': Counter({'batch_norm': 196000}), 'features.denseblock4.denselayer10.relu1': Counter(), 'features.denseblock4.denselayer10.conv1': Counter({'conv': 5017600}), 'features.denseblock4.denselayer10.norm2': Counter({'batch_norm': 31360}), 'features.denseblock4.denselayer10.relu2': Counter(), 'features.denseblock4.denselayer10.conv2': Counter({'conv': 1806336}), 'features.denseblock4.denselayer11': Counter({'conv': 7024640, 'batch_norm': 235200}), 'features.denseblock4.denselayer11.norm1': Counter({'batch_norm': 203840}), 'features.denseblock4.denselayer11.relu1': Counter(), 'features.denseblock4.denselayer11.conv1': Counter({'conv': 5218304}), 'features.denseblock4.denselayer11.norm2': Counter({'batch_norm': 31360}), 'features.denseblock4.denselayer11.relu2': Counter(), 'features.denseblock4.denselayer11.conv2': Counter({'conv': 1806336}), 'features.denseblock4.denselayer12': Counter({'conv': 7225344, 'batch_norm': 243040}), 'features.denseblock4.denselayer12.norm1': Counter({'batch_norm': 211680}), 'features.denseblock4.denselayer12.relu1': Counter(), 'features.denseblock4.denselayer12.conv1': Counter({'conv': 5419008}), 'features.denseblock4.denselayer12.norm2': Counter({'batch_norm': 31360}), 'features.denseblock4.denselayer12.relu2': Counter(), 'features.denseblock4.denselayer12.conv2': Counter({'conv': 1806336}), 'features.denseblock4.denselayer13': Counter({'conv': 7426048, 'batch_norm': 250880}), 'features.denseblock4.denselayer13.norm1': Counter({'batch_norm': 219520}), 'features.denseblock4.denselayer13.relu1': Counter(), 'features.denseblock4.denselayer13.conv1': Counter({'conv': 5619712}), 'features.denseblock4.denselayer13.norm2': Counter({'batch_norm': 31360}), 'features.denseblock4.denselayer13.relu2': Counter(), 'features.denseblock4.denselayer13.conv2': Counter({'conv': 1806336}), 'features.denseblock4.denselayer14': Counter({'conv': 7626752, 'batch_norm': 258720}), 'features.denseblock4.denselayer14.norm1': Counter({'batch_norm': 227360}), 'features.denseblock4.denselayer14.relu1': Counter(), 'features.denseblock4.denselayer14.conv1': Counter({'conv': 5820416}), 'features.denseblock4.denselayer14.norm2': Counter({'batch_norm': 31360}), 'features.denseblock4.denselayer14.relu2': Counter(), 'features.denseblock4.denselayer14.conv2': Counter({'conv': 1806336}), 'features.denseblock4.denselayer15': Counter({'conv': 7827456, 'batch_norm': 266560}), 'features.denseblock4.denselayer15.norm1': Counter({'batch_norm': 235200}), 'features.denseblock4.denselayer15.relu1': Counter(), 'features.denseblock4.denselayer15.conv1': Counter({'conv': 6021120}), 'features.denseblock4.denselayer15.norm2': Counter({'batch_norm': 31360}), 'features.denseblock4.denselayer15.relu2': Counter(), 'features.denseblock4.denselayer15.conv2': Counter({'conv': 1806336}), 'features.denseblock4.denselayer16': Counter({'conv': 8028160, 'batch_norm': 274400}), 'features.denseblock4.denselayer16.norm1': Counter({'batch_norm': 243040}), 'features.denseblock4.denselayer16.relu1': Counter(), 'features.denseblock4.denselayer16.conv1': Counter({'conv': 6221824}), 'features.denseblock4.denselayer16.norm2': Counter({'batch_norm': 31360}), 'features.denseblock4.denselayer16.relu2': Counter(), 'features.denseblock4.denselayer16.conv2': Counter({'conv': 1806336}), 'features.norm5': Counter({'batch_norm': 250880}), 'classifier': Counter({'linear': 4096})}\n",
            "| module                               | #parameters or shape   | #flops     |\n",
            "|:-------------------------------------|:-----------------------|:-----------|\n",
            "| model                                | 6.958M                 | 2.912G     |\n",
            "|  features                            |  6.954M                |  2.911G    |\n",
            "|   features.conv0                     |   9.408K               |   0.118G   |\n",
            "|    features.conv0.weight             |    (64, 3, 7, 7)       |            |\n",
            "|   features.norm0                     |   0.128K               |   4.014M   |\n",
            "|    features.norm0.weight             |    (64,)               |            |\n",
            "|    features.norm0.bias               |    (64,)               |            |\n",
            "|   features.denseblock1               |   0.335M               |   1.066G   |\n",
            "|    features.denseblock1.denselayer1  |    45.44K              |    0.144G  |\n",
            "|    features.denseblock1.denselayer2  |    49.6K               |    0.158G  |\n",
            "|    features.denseblock1.denselayer3  |    53.76K              |    0.171G  |\n",
            "|    features.denseblock1.denselayer4  |    57.92K              |    0.184G  |\n",
            "|    features.denseblock1.denselayer5  |    62.08K              |    0.198G  |\n",
            "|    features.denseblock1.denselayer6  |    66.24K              |    0.211G  |\n",
            "|   features.transition1               |   33.28K               |   0.107G   |\n",
            "|    features.transition1.norm         |    0.512K              |    4.014M  |\n",
            "|    features.transition1.conv         |    32.768K             |    0.103G  |\n",
            "|   features.denseblock2               |   0.92M                |   0.733G   |\n",
            "|    features.denseblock2.denselayer1  |    53.76K              |    42.75M  |\n",
            "|    features.denseblock2.denselayer2  |    57.92K              |    46.087M |\n",
            "|    features.denseblock2.denselayer3  |    62.08K              |    49.423M |\n",
            "|    features.denseblock2.denselayer4  |    66.24K              |    52.76M  |\n",
            "|    features.denseblock2.denselayer5  |    70.4K               |    56.097M |\n",
            "|    features.denseblock2.denselayer6  |    74.56K              |    59.433M |\n",
            "|    features.denseblock2.denselayer7  |    78.72K              |    62.77M  |\n",
            "|    features.denseblock2.denselayer8  |    82.88K              |    66.107M |\n",
            "|    features.denseblock2.denselayer9  |    87.04K              |    69.444M |\n",
            "|    features.denseblock2.denselayer10 |    91.2K               |    72.78M  |\n",
            "|    features.denseblock2.denselayer11 |    95.36K              |    76.117M |\n",
            "|    features.denseblock2.denselayer12 |    99.52K              |    79.454M |\n",
            "|   features.transition2               |   0.132M               |   0.105G   |\n",
            "|    features.transition2.norm         |    1.024K              |    2.007M  |\n",
            "|    features.transition2.conv         |    0.131M              |    0.103G  |\n",
            "|   features.denseblock3               |   2.838M               |   0.567G   |\n",
            "|    features.denseblock3.denselayer1  |    70.4K               |    14.024M |\n",
            "|    features.denseblock3.denselayer2  |    74.56K              |    14.858M |\n",
            "|    features.denseblock3.denselayer3  |    78.72K              |    15.693M |\n",
            "|    features.denseblock3.denselayer4  |    82.88K              |    16.527M |\n",
            "|    features.denseblock3.denselayer5  |    87.04K              |    17.361M |\n",
            "|    features.denseblock3.denselayer6  |    91.2K               |    18.195M |\n",
            "|    features.denseblock3.denselayer7  |    95.36K              |    19.029M |\n",
            "|    features.denseblock3.denselayer8  |    99.52K              |    19.863M |\n",
            "|    features.denseblock3.denselayer9  |    0.104M              |    20.698M |\n",
            "|    features.denseblock3.denselayer10 |    0.108M              |    21.532M |\n",
            "|    features.denseblock3.denselayer11 |    0.112M              |    22.366M |\n",
            "|    features.denseblock3.denselayer12 |    0.116M              |    23.2M   |\n",
            "|    features.denseblock3.denselayer13 |    0.12M               |    24.034M |\n",
            "|    features.denseblock3.denselayer14 |    0.124M              |    24.868M |\n",
            "|    features.denseblock3.denselayer15 |    0.129M              |    25.703M |\n",
            "|    features.denseblock3.denselayer16 |    0.133M              |    26.537M |\n",
            "|    features.denseblock3.denselayer17 |    0.137M              |    27.371M |\n",
            "|    features.denseblock3.denselayer18 |    0.141M              |    28.205M |\n",
            "|    features.denseblock3.denselayer19 |    0.145M              |    29.039M |\n",
            "|    features.denseblock3.denselayer20 |    0.149M              |    29.874M |\n",
            "|    features.denseblock3.denselayer21 |    0.154M              |    30.708M |\n",
            "|    features.denseblock3.denselayer22 |    0.158M              |    31.542M |\n",
            "|    features.denseblock3.denselayer23 |    0.162M              |    32.376M |\n",
            "|    features.denseblock3.denselayer24 |    0.166M              |    33.21M  |\n",
            "|   features.transition3               |   0.526M               |   0.104G   |\n",
            "|    features.transition3.norm         |    2.048K              |    1.004M  |\n",
            "|    features.transition3.conv         |    0.524M              |    0.103G  |\n",
            "|   features.denseblock4               |   2.158M               |   0.108G   |\n",
            "|    features.denseblock4.denselayer1  |    0.104M              |    5.174M  |\n",
            "|    features.denseblock4.denselayer2  |    0.108M              |    5.383M  |\n",
            "|    features.denseblock4.denselayer3  |    0.112M              |    5.591M  |\n",
            "|    features.denseblock4.denselayer4  |    0.116M              |    5.8M    |\n",
            "|    features.denseblock4.denselayer5  |    0.12M               |    6.009M  |\n",
            "|    features.denseblock4.denselayer6  |    0.124M              |    6.217M  |\n",
            "|    features.denseblock4.denselayer7  |    0.129M              |    6.426M  |\n",
            "|    features.denseblock4.denselayer8  |    0.133M              |    6.634M  |\n",
            "|    features.denseblock4.denselayer9  |    0.137M              |    6.843M  |\n",
            "|    features.denseblock4.denselayer10 |    0.141M              |    7.051M  |\n",
            "|    features.denseblock4.denselayer11 |    0.145M              |    7.26M   |\n",
            "|    features.denseblock4.denselayer12 |    0.149M              |    7.468M  |\n",
            "|    features.denseblock4.denselayer13 |    0.154M              |    7.677M  |\n",
            "|    features.denseblock4.denselayer14 |    0.158M              |    7.885M  |\n",
            "|    features.denseblock4.denselayer15 |    0.162M              |    8.094M  |\n",
            "|    features.denseblock4.denselayer16 |    0.166M              |    8.303M  |\n",
            "|   features.norm5                     |   2.048K               |   0.251M   |\n",
            "|    features.norm5.weight             |    (1024,)             |            |\n",
            "|    features.norm5.bias               |    (1024,)             |            |\n",
            "|  classifier                          |  4.1K                  |  4.096K    |\n",
            "|   classifier.weight                  |   (4, 1024)            |            |\n",
            "|   classifier.bias                    |   (4,)                 |            |\n",
            "DenseNet(\n",
            "  #params: 6.96M, #flops: 2.91G\n",
            "  (features): Sequential(\n",
            "    #params: 6.95M, #flops: 2.91G\n",
            "    (conv0): Conv2d(\n",
            "      3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "      #params: 9.41K, #flops: 0.12G\n",
            "    )\n",
            "    (norm0): BatchNorm2d(\n",
            "      64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "      #params: 0.13K, #flops: 4.01M\n",
            "    )\n",
            "    (relu0): ReLU(inplace=True)\n",
            "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (denseblock1): _DenseBlock(\n",
            "      #params: 0.34M, #flops: 1.07G\n",
            "      (denselayer1): _DenseLayer(\n",
            "        #params: 45.44K, #flops: 0.14G\n",
            "        (norm1): BatchNorm2d(\n",
            "          64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.13K, #flops: 1M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 8.19K, #flops: 25.69M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 2.01M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 0.12G\n",
            "        )\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        #params: 49.6K, #flops: 0.16G\n",
            "        (norm1): BatchNorm2d(\n",
            "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.19K, #flops: 1.51M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 12.29K, #flops: 38.54M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 2.01M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 0.12G\n",
            "        )\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        #params: 53.76K, #flops: 0.17G\n",
            "        (norm1): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 2.01M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 16.38K, #flops: 51.38M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 2.01M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 0.12G\n",
            "        )\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        #params: 57.92K, #flops: 0.18G\n",
            "        (norm1): BatchNorm2d(\n",
            "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.32K, #flops: 2.51M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 20.48K, #flops: 64.23M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 2.01M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 0.12G\n",
            "        )\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        #params: 62.08K, #flops: 0.2G\n",
            "        (norm1): BatchNorm2d(\n",
            "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.38K, #flops: 3.01M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 24.58K, #flops: 77.07M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 2.01M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 0.12G\n",
            "        )\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        #params: 66.24K, #flops: 0.21G\n",
            "        (norm1): BatchNorm2d(\n",
            "          224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.45K, #flops: 3.51M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 28.67K, #flops: 89.92M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 2.01M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 0.12G\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (transition1): _Transition(\n",
            "      #params: 33.28K, #flops: 0.11G\n",
            "      (norm): BatchNorm2d(\n",
            "        256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 0.51K, #flops: 4.01M\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(\n",
            "        256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 32.77K, #flops: 0.1G\n",
            "      )\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock2): _DenseBlock(\n",
            "      #params: 0.92M, #flops: 0.73G\n",
            "      (denselayer1): _DenseLayer(\n",
            "        #params: 53.76K, #flops: 42.75M\n",
            "        (norm1): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.5M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 16.38K, #flops: 12.85M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.5M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 28.9M\n",
            "        )\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        #params: 57.92K, #flops: 46.09M\n",
            "        (norm1): BatchNorm2d(\n",
            "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.32K, #flops: 0.63M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 20.48K, #flops: 16.06M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.5M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 28.9M\n",
            "        )\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        #params: 62.08K, #flops: 49.42M\n",
            "        (norm1): BatchNorm2d(\n",
            "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.38K, #flops: 0.75M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 24.58K, #flops: 19.27M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.5M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 28.9M\n",
            "        )\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        #params: 66.24K, #flops: 52.76M\n",
            "        (norm1): BatchNorm2d(\n",
            "          224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.45K, #flops: 0.88M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 28.67K, #flops: 22.48M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.5M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 28.9M\n",
            "        )\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        #params: 70.4K, #flops: 56.1M\n",
            "        (norm1): BatchNorm2d(\n",
            "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.51K, #flops: 1M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 32.77K, #flops: 25.69M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.5M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 28.9M\n",
            "        )\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        #params: 74.56K, #flops: 59.43M\n",
            "        (norm1): BatchNorm2d(\n",
            "          288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.58K, #flops: 1.13M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 28.9M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.5M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 28.9M\n",
            "        )\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        #params: 78.72K, #flops: 62.77M\n",
            "        (norm1): BatchNorm2d(\n",
            "          320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.64K, #flops: 1.25M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 40.96K, #flops: 32.11M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.5M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 28.9M\n",
            "        )\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        #params: 82.88K, #flops: 66.11M\n",
            "        (norm1): BatchNorm2d(\n",
            "          352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.7K, #flops: 1.38M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 45.06K, #flops: 35.32M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.5M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 28.9M\n",
            "        )\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        #params: 87.04K, #flops: 69.44M\n",
            "        (norm1): BatchNorm2d(\n",
            "          384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.77K, #flops: 1.51M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 49.15K, #flops: 38.54M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.5M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 28.9M\n",
            "        )\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        #params: 91.2K, #flops: 72.78M\n",
            "        (norm1): BatchNorm2d(\n",
            "          416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.83K, #flops: 1.63M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 53.25K, #flops: 41.75M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.5M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 28.9M\n",
            "        )\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        #params: 95.36K, #flops: 76.12M\n",
            "        (norm1): BatchNorm2d(\n",
            "          448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.9K, #flops: 1.76M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 57.34K, #flops: 44.96M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.5M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 28.9M\n",
            "        )\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        #params: 99.52K, #flops: 79.45M\n",
            "        (norm1): BatchNorm2d(\n",
            "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.96K, #flops: 1.88M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 61.44K, #flops: 48.17M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.5M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 28.9M\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (transition2): _Transition(\n",
            "      #params: 0.13M, #flops: 0.1G\n",
            "      (norm): BatchNorm2d(\n",
            "        512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 1.02K, #flops: 2.01M\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(\n",
            "        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 0.13M, #flops: 0.1G\n",
            "      )\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock3): _DenseBlock(\n",
            "      #params: 2.84M, #flops: 0.57G\n",
            "      (denselayer1): _DenseLayer(\n",
            "        #params: 70.4K, #flops: 14.02M\n",
            "        (norm1): BatchNorm2d(\n",
            "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.51K, #flops: 0.25M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 32.77K, #flops: 6.42M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.13M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 7.23M\n",
            "        )\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        #params: 74.56K, #flops: 14.86M\n",
            "        (norm1): BatchNorm2d(\n",
            "          288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.58K, #flops: 0.28M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 7.23M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.13M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 7.23M\n",
            "        )\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        #params: 78.72K, #flops: 15.69M\n",
            "        (norm1): BatchNorm2d(\n",
            "          320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.64K, #flops: 0.31M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 40.96K, #flops: 8.03M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.13M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 7.23M\n",
            "        )\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        #params: 82.88K, #flops: 16.53M\n",
            "        (norm1): BatchNorm2d(\n",
            "          352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.7K, #flops: 0.34M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 45.06K, #flops: 8.83M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.13M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 7.23M\n",
            "        )\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        #params: 87.04K, #flops: 17.36M\n",
            "        (norm1): BatchNorm2d(\n",
            "          384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.77K, #flops: 0.38M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 49.15K, #flops: 9.63M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.13M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 7.23M\n",
            "        )\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        #params: 91.2K, #flops: 18.2M\n",
            "        (norm1): BatchNorm2d(\n",
            "          416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.83K, #flops: 0.41M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 53.25K, #flops: 10.44M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.13M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 7.23M\n",
            "        )\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        #params: 95.36K, #flops: 19.03M\n",
            "        (norm1): BatchNorm2d(\n",
            "          448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.9K, #flops: 0.44M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 57.34K, #flops: 11.24M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.13M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 7.23M\n",
            "        )\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        #params: 99.52K, #flops: 19.86M\n",
            "        (norm1): BatchNorm2d(\n",
            "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.96K, #flops: 0.47M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 61.44K, #flops: 12.04M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.13M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 7.23M\n",
            "        )\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        #params: 0.1M, #flops: 20.7M\n",
            "        (norm1): BatchNorm2d(\n",
            "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.02K, #flops: 0.5M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 65.54K, #flops: 12.85M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.13M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 7.23M\n",
            "        )\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        #params: 0.11M, #flops: 21.53M\n",
            "        (norm1): BatchNorm2d(\n",
            "          544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.09K, #flops: 0.53M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 69.63K, #flops: 13.65M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.13M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 7.23M\n",
            "        )\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        #params: 0.11M, #flops: 22.37M\n",
            "        (norm1): BatchNorm2d(\n",
            "          576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.15K, #flops: 0.56M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 73.73K, #flops: 14.45M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.13M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 7.23M\n",
            "        )\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        #params: 0.12M, #flops: 23.2M\n",
            "        (norm1): BatchNorm2d(\n",
            "          608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.22K, #flops: 0.6M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 77.82K, #flops: 15.25M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.13M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 7.23M\n",
            "        )\n",
            "      )\n",
            "      (denselayer13): _DenseLayer(\n",
            "        #params: 0.12M, #flops: 24.03M\n",
            "        (norm1): BatchNorm2d(\n",
            "          640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.28K, #flops: 0.63M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 81.92K, #flops: 16.06M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.13M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 7.23M\n",
            "        )\n",
            "      )\n",
            "      (denselayer14): _DenseLayer(\n",
            "        #params: 0.12M, #flops: 24.87M\n",
            "        (norm1): BatchNorm2d(\n",
            "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.34K, #flops: 0.66M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 86.02K, #flops: 16.86M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.13M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 7.23M\n",
            "        )\n",
            "      )\n",
            "      (denselayer15): _DenseLayer(\n",
            "        #params: 0.13M, #flops: 25.7M\n",
            "        (norm1): BatchNorm2d(\n",
            "          704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.41K, #flops: 0.69M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 90.11K, #flops: 17.66M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.13M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 7.23M\n",
            "        )\n",
            "      )\n",
            "      (denselayer16): _DenseLayer(\n",
            "        #params: 0.13M, #flops: 26.54M\n",
            "        (norm1): BatchNorm2d(\n",
            "          736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.47K, #flops: 0.72M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 94.21K, #flops: 18.46M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.13M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 7.23M\n",
            "        )\n",
            "      )\n",
            "      (denselayer17): _DenseLayer(\n",
            "        #params: 0.14M, #flops: 27.37M\n",
            "        (norm1): BatchNorm2d(\n",
            "          768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.54K, #flops: 0.75M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 98.3K, #flops: 19.27M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.13M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 7.23M\n",
            "        )\n",
            "      )\n",
            "      (denselayer18): _DenseLayer(\n",
            "        #params: 0.14M, #flops: 28.21M\n",
            "        (norm1): BatchNorm2d(\n",
            "          800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.6K, #flops: 0.78M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 0.1M, #flops: 20.07M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.13M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 7.23M\n",
            "        )\n",
            "      )\n",
            "      (denselayer19): _DenseLayer(\n",
            "        #params: 0.15M, #flops: 29.04M\n",
            "        (norm1): BatchNorm2d(\n",
            "          832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.66K, #flops: 0.82M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 0.11M, #flops: 20.87M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.13M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 7.23M\n",
            "        )\n",
            "      )\n",
            "      (denselayer20): _DenseLayer(\n",
            "        #params: 0.15M, #flops: 29.87M\n",
            "        (norm1): BatchNorm2d(\n",
            "          864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.73K, #flops: 0.85M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 0.11M, #flops: 21.68M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.13M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 7.23M\n",
            "        )\n",
            "      )\n",
            "      (denselayer21): _DenseLayer(\n",
            "        #params: 0.15M, #flops: 30.71M\n",
            "        (norm1): BatchNorm2d(\n",
            "          896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.79K, #flops: 0.88M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 0.11M, #flops: 22.48M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.13M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 7.23M\n",
            "        )\n",
            "      )\n",
            "      (denselayer22): _DenseLayer(\n",
            "        #params: 0.16M, #flops: 31.54M\n",
            "        (norm1): BatchNorm2d(\n",
            "          928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.86K, #flops: 0.91M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 0.12M, #flops: 23.28M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.13M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 7.23M\n",
            "        )\n",
            "      )\n",
            "      (denselayer23): _DenseLayer(\n",
            "        #params: 0.16M, #flops: 32.38M\n",
            "        (norm1): BatchNorm2d(\n",
            "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.92K, #flops: 0.94M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 0.12M, #flops: 24.08M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.13M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 7.23M\n",
            "        )\n",
            "      )\n",
            "      (denselayer24): _DenseLayer(\n",
            "        #params: 0.17M, #flops: 33.21M\n",
            "        (norm1): BatchNorm2d(\n",
            "          992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.98K, #flops: 0.97M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 0.13M, #flops: 24.89M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 0.13M\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 7.23M\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (transition3): _Transition(\n",
            "      #params: 0.53M, #flops: 0.1G\n",
            "      (norm): BatchNorm2d(\n",
            "        1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "        #params: 2.05K, #flops: 1M\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(\n",
            "        1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        #params: 0.52M, #flops: 0.1G\n",
            "      )\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock4): _DenseBlock(\n",
            "      #params: 2.16M, #flops: 0.11G\n",
            "      (denselayer1): _DenseLayer(\n",
            "        #params: 0.1M, #flops: 5.17M\n",
            "        (norm1): BatchNorm2d(\n",
            "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.02K, #flops: 0.13M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 65.54K, #flops: 3.21M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 31.36K\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 1.81M\n",
            "        )\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        #params: 0.11M, #flops: 5.38M\n",
            "        (norm1): BatchNorm2d(\n",
            "          544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.09K, #flops: 0.13M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 69.63K, #flops: 3.41M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 31.36K\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 1.81M\n",
            "        )\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        #params: 0.11M, #flops: 5.59M\n",
            "        (norm1): BatchNorm2d(\n",
            "          576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.15K, #flops: 0.14M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 73.73K, #flops: 3.61M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 31.36K\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 1.81M\n",
            "        )\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        #params: 0.12M, #flops: 5.8M\n",
            "        (norm1): BatchNorm2d(\n",
            "          608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.22K, #flops: 0.15M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 77.82K, #flops: 3.81M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 31.36K\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 1.81M\n",
            "        )\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        #params: 0.12M, #flops: 6.01M\n",
            "        (norm1): BatchNorm2d(\n",
            "          640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.28K, #flops: 0.16M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 81.92K, #flops: 4.01M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 31.36K\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 1.81M\n",
            "        )\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        #params: 0.12M, #flops: 6.22M\n",
            "        (norm1): BatchNorm2d(\n",
            "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.34K, #flops: 0.16M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 86.02K, #flops: 4.21M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 31.36K\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 1.81M\n",
            "        )\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        #params: 0.13M, #flops: 6.43M\n",
            "        (norm1): BatchNorm2d(\n",
            "          704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.41K, #flops: 0.17M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 90.11K, #flops: 4.42M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 31.36K\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 1.81M\n",
            "        )\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        #params: 0.13M, #flops: 6.63M\n",
            "        (norm1): BatchNorm2d(\n",
            "          736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.47K, #flops: 0.18M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 94.21K, #flops: 4.62M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 31.36K\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 1.81M\n",
            "        )\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        #params: 0.14M, #flops: 6.84M\n",
            "        (norm1): BatchNorm2d(\n",
            "          768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.54K, #flops: 0.19M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 98.3K, #flops: 4.82M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 31.36K\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 1.81M\n",
            "        )\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        #params: 0.14M, #flops: 7.05M\n",
            "        (norm1): BatchNorm2d(\n",
            "          800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.6K, #flops: 0.2M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 0.1M, #flops: 5.02M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 31.36K\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 1.81M\n",
            "        )\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        #params: 0.15M, #flops: 7.26M\n",
            "        (norm1): BatchNorm2d(\n",
            "          832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.66K, #flops: 0.2M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 0.11M, #flops: 5.22M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 31.36K\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 1.81M\n",
            "        )\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        #params: 0.15M, #flops: 7.47M\n",
            "        (norm1): BatchNorm2d(\n",
            "          864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.73K, #flops: 0.21M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 0.11M, #flops: 5.42M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 31.36K\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 1.81M\n",
            "        )\n",
            "      )\n",
            "      (denselayer13): _DenseLayer(\n",
            "        #params: 0.15M, #flops: 7.68M\n",
            "        (norm1): BatchNorm2d(\n",
            "          896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.79K, #flops: 0.22M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 0.11M, #flops: 5.62M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 31.36K\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 1.81M\n",
            "        )\n",
            "      )\n",
            "      (denselayer14): _DenseLayer(\n",
            "        #params: 0.16M, #flops: 7.89M\n",
            "        (norm1): BatchNorm2d(\n",
            "          928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.86K, #flops: 0.23M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 0.12M, #flops: 5.82M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 31.36K\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 1.81M\n",
            "        )\n",
            "      )\n",
            "      (denselayer15): _DenseLayer(\n",
            "        #params: 0.16M, #flops: 8.09M\n",
            "        (norm1): BatchNorm2d(\n",
            "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.92K, #flops: 0.24M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 0.12M, #flops: 6.02M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 31.36K\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 1.81M\n",
            "        )\n",
            "      )\n",
            "      (denselayer16): _DenseLayer(\n",
            "        #params: 0.17M, #flops: 8.3M\n",
            "        (norm1): BatchNorm2d(\n",
            "          992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 1.98K, #flops: 0.24M\n",
            "        )\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(\n",
            "          992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          #params: 0.13M, #flops: 6.22M\n",
            "        )\n",
            "        (norm2): BatchNorm2d(\n",
            "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "          #params: 0.26K, #flops: 31.36K\n",
            "        )\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(\n",
            "          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          #params: 36.86K, #flops: 1.81M\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (norm5): BatchNorm2d(\n",
            "      1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "      #params: 2.05K, #flops: 0.25M\n",
            "    )\n",
            "  )\n",
            "  (classifier): Linear(\n",
            "    in_features=1024, out_features=4, bias=True\n",
            "    #params: 4.1K, #flops: 4.1K\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "analyze_model_flops(bert_model, dummy_input_bert, \"BERT-uncased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iE_G4oi_gPeQ",
        "outputId": "39537c09-af30-4579-faa0-73b3a755b29e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add encountered 27 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::embedding encountered 3 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add_ encountered 1 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::rsub encountered 1 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::scaled_dot_product_attention encountered 12 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::gelu encountered 12 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::tanh encountered 1 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
            "encoder.layer.0.attention.self.dropout, encoder.layer.1.attention.self.dropout, encoder.layer.10.attention.self.dropout, encoder.layer.11.attention.self.dropout, encoder.layer.2.attention.self.dropout, encoder.layer.3.attention.self.dropout, encoder.layer.4.attention.self.dropout, encoder.layer.5.attention.self.dropout, encoder.layer.6.attention.self.dropout, encoder.layer.7.attention.self.dropout, encoder.layer.8.attention.self.dropout, encoder.layer.9.attention.self.dropout\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total FLOPs for BERT-uncased: 10884513792\n",
            "FLOPs by operator for BERT-uncased: Counter({'linear': 10872225792, 'layer_norm': 12288000})\n",
            "FLOPs by module for BERT-uncased: Counter({'': 10884513792, 'encoder': 10883432448, 'encoder.layer': 10883432448, 'encoder.layer.0': 906952704, 'encoder.layer.1': 906952704, 'encoder.layer.2': 906952704, 'encoder.layer.3': 906952704, 'encoder.layer.4': 906952704, 'encoder.layer.5': 906952704, 'encoder.layer.6': 906952704, 'encoder.layer.7': 906952704, 'encoder.layer.8': 906952704, 'encoder.layer.9': 906952704, 'encoder.layer.10': 906952704, 'encoder.layer.11': 906952704, 'encoder.layer.0.attention': 302481408, 'encoder.layer.0.output': 302481408, 'encoder.layer.1.attention': 302481408, 'encoder.layer.1.output': 302481408, 'encoder.layer.2.attention': 302481408, 'encoder.layer.2.output': 302481408, 'encoder.layer.3.attention': 302481408, 'encoder.layer.3.output': 302481408, 'encoder.layer.4.attention': 302481408, 'encoder.layer.4.output': 302481408, 'encoder.layer.5.attention': 302481408, 'encoder.layer.5.output': 302481408, 'encoder.layer.6.attention': 302481408, 'encoder.layer.6.output': 302481408, 'encoder.layer.7.attention': 302481408, 'encoder.layer.7.output': 302481408, 'encoder.layer.8.attention': 302481408, 'encoder.layer.8.output': 302481408, 'encoder.layer.9.attention': 302481408, 'encoder.layer.9.output': 302481408, 'encoder.layer.10.attention': 302481408, 'encoder.layer.10.output': 302481408, 'encoder.layer.11.attention': 302481408, 'encoder.layer.11.output': 302481408, 'encoder.layer.0.intermediate': 301989888, 'encoder.layer.0.intermediate.dense': 301989888, 'encoder.layer.0.output.dense': 301989888, 'encoder.layer.1.intermediate': 301989888, 'encoder.layer.1.intermediate.dense': 301989888, 'encoder.layer.1.output.dense': 301989888, 'encoder.layer.2.intermediate': 301989888, 'encoder.layer.2.intermediate.dense': 301989888, 'encoder.layer.2.output.dense': 301989888, 'encoder.layer.3.intermediate': 301989888, 'encoder.layer.3.intermediate.dense': 301989888, 'encoder.layer.3.output.dense': 301989888, 'encoder.layer.4.intermediate': 301989888, 'encoder.layer.4.intermediate.dense': 301989888, 'encoder.layer.4.output.dense': 301989888, 'encoder.layer.5.intermediate': 301989888, 'encoder.layer.5.intermediate.dense': 301989888, 'encoder.layer.5.output.dense': 301989888, 'encoder.layer.6.intermediate': 301989888, 'encoder.layer.6.intermediate.dense': 301989888, 'encoder.layer.6.output.dense': 301989888, 'encoder.layer.7.intermediate': 301989888, 'encoder.layer.7.intermediate.dense': 301989888, 'encoder.layer.7.output.dense': 301989888, 'encoder.layer.8.intermediate': 301989888, 'encoder.layer.8.intermediate.dense': 301989888, 'encoder.layer.8.output.dense': 301989888, 'encoder.layer.9.intermediate': 301989888, 'encoder.layer.9.intermediate.dense': 301989888, 'encoder.layer.9.output.dense': 301989888, 'encoder.layer.10.intermediate': 301989888, 'encoder.layer.10.intermediate.dense': 301989888, 'encoder.layer.10.output.dense': 301989888, 'encoder.layer.11.intermediate': 301989888, 'encoder.layer.11.intermediate.dense': 301989888, 'encoder.layer.11.output.dense': 301989888, 'encoder.layer.0.attention.self': 226492416, 'encoder.layer.1.attention.self': 226492416, 'encoder.layer.2.attention.self': 226492416, 'encoder.layer.3.attention.self': 226492416, 'encoder.layer.4.attention.self': 226492416, 'encoder.layer.5.attention.self': 226492416, 'encoder.layer.6.attention.self': 226492416, 'encoder.layer.7.attention.self': 226492416, 'encoder.layer.8.attention.self': 226492416, 'encoder.layer.9.attention.self': 226492416, 'encoder.layer.10.attention.self': 226492416, 'encoder.layer.11.attention.self': 226492416, 'encoder.layer.0.attention.output': 75988992, 'encoder.layer.1.attention.output': 75988992, 'encoder.layer.2.attention.output': 75988992, 'encoder.layer.3.attention.output': 75988992, 'encoder.layer.4.attention.output': 75988992, 'encoder.layer.5.attention.output': 75988992, 'encoder.layer.6.attention.output': 75988992, 'encoder.layer.7.attention.output': 75988992, 'encoder.layer.8.attention.output': 75988992, 'encoder.layer.9.attention.output': 75988992, 'encoder.layer.10.attention.output': 75988992, 'encoder.layer.11.attention.output': 75988992, 'encoder.layer.0.attention.self.query': 75497472, 'encoder.layer.0.attention.self.key': 75497472, 'encoder.layer.0.attention.self.value': 75497472, 'encoder.layer.0.attention.output.dense': 75497472, 'encoder.layer.1.attention.self.query': 75497472, 'encoder.layer.1.attention.self.key': 75497472, 'encoder.layer.1.attention.self.value': 75497472, 'encoder.layer.1.attention.output.dense': 75497472, 'encoder.layer.2.attention.self.query': 75497472, 'encoder.layer.2.attention.self.key': 75497472, 'encoder.layer.2.attention.self.value': 75497472, 'encoder.layer.2.attention.output.dense': 75497472, 'encoder.layer.3.attention.self.query': 75497472, 'encoder.layer.3.attention.self.key': 75497472, 'encoder.layer.3.attention.self.value': 75497472, 'encoder.layer.3.attention.output.dense': 75497472, 'encoder.layer.4.attention.self.query': 75497472, 'encoder.layer.4.attention.self.key': 75497472, 'encoder.layer.4.attention.self.value': 75497472, 'encoder.layer.4.attention.output.dense': 75497472, 'encoder.layer.5.attention.self.query': 75497472, 'encoder.layer.5.attention.self.key': 75497472, 'encoder.layer.5.attention.self.value': 75497472, 'encoder.layer.5.attention.output.dense': 75497472, 'encoder.layer.6.attention.self.query': 75497472, 'encoder.layer.6.attention.self.key': 75497472, 'encoder.layer.6.attention.self.value': 75497472, 'encoder.layer.6.attention.output.dense': 75497472, 'encoder.layer.7.attention.self.query': 75497472, 'encoder.layer.7.attention.self.key': 75497472, 'encoder.layer.7.attention.self.value': 75497472, 'encoder.layer.7.attention.output.dense': 75497472, 'encoder.layer.8.attention.self.query': 75497472, 'encoder.layer.8.attention.self.key': 75497472, 'encoder.layer.8.attention.self.value': 75497472, 'encoder.layer.8.attention.output.dense': 75497472, 'encoder.layer.9.attention.self.query': 75497472, 'encoder.layer.9.attention.self.key': 75497472, 'encoder.layer.9.attention.self.value': 75497472, 'encoder.layer.9.attention.output.dense': 75497472, 'encoder.layer.10.attention.self.query': 75497472, 'encoder.layer.10.attention.self.key': 75497472, 'encoder.layer.10.attention.self.value': 75497472, 'encoder.layer.10.attention.output.dense': 75497472, 'encoder.layer.11.attention.self.query': 75497472, 'encoder.layer.11.attention.self.key': 75497472, 'encoder.layer.11.attention.self.value': 75497472, 'encoder.layer.11.attention.output.dense': 75497472, 'pooler': 589824, 'pooler.dense': 589824, 'embeddings': 491520, 'embeddings.LayerNorm': 491520, 'encoder.layer.0.attention.output.LayerNorm': 491520, 'encoder.layer.0.output.LayerNorm': 491520, 'encoder.layer.1.attention.output.LayerNorm': 491520, 'encoder.layer.1.output.LayerNorm': 491520, 'encoder.layer.2.attention.output.LayerNorm': 491520, 'encoder.layer.2.output.LayerNorm': 491520, 'encoder.layer.3.attention.output.LayerNorm': 491520, 'encoder.layer.3.output.LayerNorm': 491520, 'encoder.layer.4.attention.output.LayerNorm': 491520, 'encoder.layer.4.output.LayerNorm': 491520, 'encoder.layer.5.attention.output.LayerNorm': 491520, 'encoder.layer.5.output.LayerNorm': 491520, 'encoder.layer.6.attention.output.LayerNorm': 491520, 'encoder.layer.6.output.LayerNorm': 491520, 'encoder.layer.7.attention.output.LayerNorm': 491520, 'encoder.layer.7.output.LayerNorm': 491520, 'encoder.layer.8.attention.output.LayerNorm': 491520, 'encoder.layer.8.output.LayerNorm': 491520, 'encoder.layer.9.attention.output.LayerNorm': 491520, 'encoder.layer.9.output.LayerNorm': 491520, 'encoder.layer.10.attention.output.LayerNorm': 491520, 'encoder.layer.10.output.LayerNorm': 491520, 'encoder.layer.11.attention.output.LayerNorm': 491520, 'encoder.layer.11.output.LayerNorm': 491520, 'embeddings.word_embeddings': 0, 'embeddings.position_embeddings': 0, 'embeddings.token_type_embeddings': 0, 'embeddings.dropout': 0, 'encoder.layer.0.attention.self.dropout': 0, 'encoder.layer.0.attention.output.dropout': 0, 'encoder.layer.0.intermediate.intermediate_act_fn': 0, 'encoder.layer.0.output.dropout': 0, 'encoder.layer.1.attention.self.dropout': 0, 'encoder.layer.1.attention.output.dropout': 0, 'encoder.layer.1.intermediate.intermediate_act_fn': 0, 'encoder.layer.1.output.dropout': 0, 'encoder.layer.2.attention.self.dropout': 0, 'encoder.layer.2.attention.output.dropout': 0, 'encoder.layer.2.intermediate.intermediate_act_fn': 0, 'encoder.layer.2.output.dropout': 0, 'encoder.layer.3.attention.self.dropout': 0, 'encoder.layer.3.attention.output.dropout': 0, 'encoder.layer.3.intermediate.intermediate_act_fn': 0, 'encoder.layer.3.output.dropout': 0, 'encoder.layer.4.attention.self.dropout': 0, 'encoder.layer.4.attention.output.dropout': 0, 'encoder.layer.4.intermediate.intermediate_act_fn': 0, 'encoder.layer.4.output.dropout': 0, 'encoder.layer.5.attention.self.dropout': 0, 'encoder.layer.5.attention.output.dropout': 0, 'encoder.layer.5.intermediate.intermediate_act_fn': 0, 'encoder.layer.5.output.dropout': 0, 'encoder.layer.6.attention.self.dropout': 0, 'encoder.layer.6.attention.output.dropout': 0, 'encoder.layer.6.intermediate.intermediate_act_fn': 0, 'encoder.layer.6.output.dropout': 0, 'encoder.layer.7.attention.self.dropout': 0, 'encoder.layer.7.attention.output.dropout': 0, 'encoder.layer.7.intermediate.intermediate_act_fn': 0, 'encoder.layer.7.output.dropout': 0, 'encoder.layer.8.attention.self.dropout': 0, 'encoder.layer.8.attention.output.dropout': 0, 'encoder.layer.8.intermediate.intermediate_act_fn': 0, 'encoder.layer.8.output.dropout': 0, 'encoder.layer.9.attention.self.dropout': 0, 'encoder.layer.9.attention.output.dropout': 0, 'encoder.layer.9.intermediate.intermediate_act_fn': 0, 'encoder.layer.9.output.dropout': 0, 'encoder.layer.10.attention.self.dropout': 0, 'encoder.layer.10.attention.output.dropout': 0, 'encoder.layer.10.intermediate.intermediate_act_fn': 0, 'encoder.layer.10.output.dropout': 0, 'encoder.layer.11.attention.self.dropout': 0, 'encoder.layer.11.attention.output.dropout': 0, 'encoder.layer.11.intermediate.intermediate_act_fn': 0, 'encoder.layer.11.output.dropout': 0, 'pooler.activation': 0})\n",
            "FLOPs by module and operator for BERT-uncased: {'': Counter({'linear': 10872225792, 'layer_norm': 12288000}), 'embeddings': Counter({'layer_norm': 491520}), 'embeddings.word_embeddings': Counter(), 'embeddings.position_embeddings': Counter(), 'embeddings.token_type_embeddings': Counter(), 'embeddings.LayerNorm': Counter({'layer_norm': 491520}), 'embeddings.dropout': Counter(), 'encoder': Counter({'linear': 10871635968, 'layer_norm': 11796480}), 'encoder.layer': Counter({'linear': 10871635968, 'layer_norm': 11796480}), 'encoder.layer.0': Counter({'linear': 905969664, 'layer_norm': 983040}), 'encoder.layer.0.attention': Counter({'linear': 301989888, 'layer_norm': 491520}), 'encoder.layer.0.attention.self': Counter({'linear': 226492416}), 'encoder.layer.0.attention.self.query': Counter({'linear': 75497472}), 'encoder.layer.0.attention.self.key': Counter({'linear': 75497472}), 'encoder.layer.0.attention.self.value': Counter({'linear': 75497472}), 'encoder.layer.0.attention.self.dropout': Counter(), 'encoder.layer.0.attention.output': Counter({'linear': 75497472, 'layer_norm': 491520}), 'encoder.layer.0.attention.output.dense': Counter({'linear': 75497472}), 'encoder.layer.0.attention.output.LayerNorm': Counter({'layer_norm': 491520}), 'encoder.layer.0.attention.output.dropout': Counter(), 'encoder.layer.0.intermediate': Counter({'linear': 301989888}), 'encoder.layer.0.intermediate.dense': Counter({'linear': 301989888}), 'encoder.layer.0.intermediate.intermediate_act_fn': Counter(), 'encoder.layer.0.output': Counter({'linear': 301989888, 'layer_norm': 491520}), 'encoder.layer.0.output.dense': Counter({'linear': 301989888}), 'encoder.layer.0.output.LayerNorm': Counter({'layer_norm': 491520}), 'encoder.layer.0.output.dropout': Counter(), 'encoder.layer.1': Counter({'linear': 905969664, 'layer_norm': 983040}), 'encoder.layer.1.attention': Counter({'linear': 301989888, 'layer_norm': 491520}), 'encoder.layer.1.attention.self': Counter({'linear': 226492416}), 'encoder.layer.1.attention.self.query': Counter({'linear': 75497472}), 'encoder.layer.1.attention.self.key': Counter({'linear': 75497472}), 'encoder.layer.1.attention.self.value': Counter({'linear': 75497472}), 'encoder.layer.1.attention.self.dropout': Counter(), 'encoder.layer.1.attention.output': Counter({'linear': 75497472, 'layer_norm': 491520}), 'encoder.layer.1.attention.output.dense': Counter({'linear': 75497472}), 'encoder.layer.1.attention.output.LayerNorm': Counter({'layer_norm': 491520}), 'encoder.layer.1.attention.output.dropout': Counter(), 'encoder.layer.1.intermediate': Counter({'linear': 301989888}), 'encoder.layer.1.intermediate.dense': Counter({'linear': 301989888}), 'encoder.layer.1.intermediate.intermediate_act_fn': Counter(), 'encoder.layer.1.output': Counter({'linear': 301989888, 'layer_norm': 491520}), 'encoder.layer.1.output.dense': Counter({'linear': 301989888}), 'encoder.layer.1.output.LayerNorm': Counter({'layer_norm': 491520}), 'encoder.layer.1.output.dropout': Counter(), 'encoder.layer.2': Counter({'linear': 905969664, 'layer_norm': 983040}), 'encoder.layer.2.attention': Counter({'linear': 301989888, 'layer_norm': 491520}), 'encoder.layer.2.attention.self': Counter({'linear': 226492416}), 'encoder.layer.2.attention.self.query': Counter({'linear': 75497472}), 'encoder.layer.2.attention.self.key': Counter({'linear': 75497472}), 'encoder.layer.2.attention.self.value': Counter({'linear': 75497472}), 'encoder.layer.2.attention.self.dropout': Counter(), 'encoder.layer.2.attention.output': Counter({'linear': 75497472, 'layer_norm': 491520}), 'encoder.layer.2.attention.output.dense': Counter({'linear': 75497472}), 'encoder.layer.2.attention.output.LayerNorm': Counter({'layer_norm': 491520}), 'encoder.layer.2.attention.output.dropout': Counter(), 'encoder.layer.2.intermediate': Counter({'linear': 301989888}), 'encoder.layer.2.intermediate.dense': Counter({'linear': 301989888}), 'encoder.layer.2.intermediate.intermediate_act_fn': Counter(), 'encoder.layer.2.output': Counter({'linear': 301989888, 'layer_norm': 491520}), 'encoder.layer.2.output.dense': Counter({'linear': 301989888}), 'encoder.layer.2.output.LayerNorm': Counter({'layer_norm': 491520}), 'encoder.layer.2.output.dropout': Counter(), 'encoder.layer.3': Counter({'linear': 905969664, 'layer_norm': 983040}), 'encoder.layer.3.attention': Counter({'linear': 301989888, 'layer_norm': 491520}), 'encoder.layer.3.attention.self': Counter({'linear': 226492416}), 'encoder.layer.3.attention.self.query': Counter({'linear': 75497472}), 'encoder.layer.3.attention.self.key': Counter({'linear': 75497472}), 'encoder.layer.3.attention.self.value': Counter({'linear': 75497472}), 'encoder.layer.3.attention.self.dropout': Counter(), 'encoder.layer.3.attention.output': Counter({'linear': 75497472, 'layer_norm': 491520}), 'encoder.layer.3.attention.output.dense': Counter({'linear': 75497472}), 'encoder.layer.3.attention.output.LayerNorm': Counter({'layer_norm': 491520}), 'encoder.layer.3.attention.output.dropout': Counter(), 'encoder.layer.3.intermediate': Counter({'linear': 301989888}), 'encoder.layer.3.intermediate.dense': Counter({'linear': 301989888}), 'encoder.layer.3.intermediate.intermediate_act_fn': Counter(), 'encoder.layer.3.output': Counter({'linear': 301989888, 'layer_norm': 491520}), 'encoder.layer.3.output.dense': Counter({'linear': 301989888}), 'encoder.layer.3.output.LayerNorm': Counter({'layer_norm': 491520}), 'encoder.layer.3.output.dropout': Counter(), 'encoder.layer.4': Counter({'linear': 905969664, 'layer_norm': 983040}), 'encoder.layer.4.attention': Counter({'linear': 301989888, 'layer_norm': 491520}), 'encoder.layer.4.attention.self': Counter({'linear': 226492416}), 'encoder.layer.4.attention.self.query': Counter({'linear': 75497472}), 'encoder.layer.4.attention.self.key': Counter({'linear': 75497472}), 'encoder.layer.4.attention.self.value': Counter({'linear': 75497472}), 'encoder.layer.4.attention.self.dropout': Counter(), 'encoder.layer.4.attention.output': Counter({'linear': 75497472, 'layer_norm': 491520}), 'encoder.layer.4.attention.output.dense': Counter({'linear': 75497472}), 'encoder.layer.4.attention.output.LayerNorm': Counter({'layer_norm': 491520}), 'encoder.layer.4.attention.output.dropout': Counter(), 'encoder.layer.4.intermediate': Counter({'linear': 301989888}), 'encoder.layer.4.intermediate.dense': Counter({'linear': 301989888}), 'encoder.layer.4.intermediate.intermediate_act_fn': Counter(), 'encoder.layer.4.output': Counter({'linear': 301989888, 'layer_norm': 491520}), 'encoder.layer.4.output.dense': Counter({'linear': 301989888}), 'encoder.layer.4.output.LayerNorm': Counter({'layer_norm': 491520}), 'encoder.layer.4.output.dropout': Counter(), 'encoder.layer.5': Counter({'linear': 905969664, 'layer_norm': 983040}), 'encoder.layer.5.attention': Counter({'linear': 301989888, 'layer_norm': 491520}), 'encoder.layer.5.attention.self': Counter({'linear': 226492416}), 'encoder.layer.5.attention.self.query': Counter({'linear': 75497472}), 'encoder.layer.5.attention.self.key': Counter({'linear': 75497472}), 'encoder.layer.5.attention.self.value': Counter({'linear': 75497472}), 'encoder.layer.5.attention.self.dropout': Counter(), 'encoder.layer.5.attention.output': Counter({'linear': 75497472, 'layer_norm': 491520}), 'encoder.layer.5.attention.output.dense': Counter({'linear': 75497472}), 'encoder.layer.5.attention.output.LayerNorm': Counter({'layer_norm': 491520}), 'encoder.layer.5.attention.output.dropout': Counter(), 'encoder.layer.5.intermediate': Counter({'linear': 301989888}), 'encoder.layer.5.intermediate.dense': Counter({'linear': 301989888}), 'encoder.layer.5.intermediate.intermediate_act_fn': Counter(), 'encoder.layer.5.output': Counter({'linear': 301989888, 'layer_norm': 491520}), 'encoder.layer.5.output.dense': Counter({'linear': 301989888}), 'encoder.layer.5.output.LayerNorm': Counter({'layer_norm': 491520}), 'encoder.layer.5.output.dropout': Counter(), 'encoder.layer.6': Counter({'linear': 905969664, 'layer_norm': 983040}), 'encoder.layer.6.attention': Counter({'linear': 301989888, 'layer_norm': 491520}), 'encoder.layer.6.attention.self': Counter({'linear': 226492416}), 'encoder.layer.6.attention.self.query': Counter({'linear': 75497472}), 'encoder.layer.6.attention.self.key': Counter({'linear': 75497472}), 'encoder.layer.6.attention.self.value': Counter({'linear': 75497472}), 'encoder.layer.6.attention.self.dropout': Counter(), 'encoder.layer.6.attention.output': Counter({'linear': 75497472, 'layer_norm': 491520}), 'encoder.layer.6.attention.output.dense': Counter({'linear': 75497472}), 'encoder.layer.6.attention.output.LayerNorm': Counter({'layer_norm': 491520}), 'encoder.layer.6.attention.output.dropout': Counter(), 'encoder.layer.6.intermediate': Counter({'linear': 301989888}), 'encoder.layer.6.intermediate.dense': Counter({'linear': 301989888}), 'encoder.layer.6.intermediate.intermediate_act_fn': Counter(), 'encoder.layer.6.output': Counter({'linear': 301989888, 'layer_norm': 491520}), 'encoder.layer.6.output.dense': Counter({'linear': 301989888}), 'encoder.layer.6.output.LayerNorm': Counter({'layer_norm': 491520}), 'encoder.layer.6.output.dropout': Counter(), 'encoder.layer.7': Counter({'linear': 905969664, 'layer_norm': 983040}), 'encoder.layer.7.attention': Counter({'linear': 301989888, 'layer_norm': 491520}), 'encoder.layer.7.attention.self': Counter({'linear': 226492416}), 'encoder.layer.7.attention.self.query': Counter({'linear': 75497472}), 'encoder.layer.7.attention.self.key': Counter({'linear': 75497472}), 'encoder.layer.7.attention.self.value': Counter({'linear': 75497472}), 'encoder.layer.7.attention.self.dropout': Counter(), 'encoder.layer.7.attention.output': Counter({'linear': 75497472, 'layer_norm': 491520}), 'encoder.layer.7.attention.output.dense': Counter({'linear': 75497472}), 'encoder.layer.7.attention.output.LayerNorm': Counter({'layer_norm': 491520}), 'encoder.layer.7.attention.output.dropout': Counter(), 'encoder.layer.7.intermediate': Counter({'linear': 301989888}), 'encoder.layer.7.intermediate.dense': Counter({'linear': 301989888}), 'encoder.layer.7.intermediate.intermediate_act_fn': Counter(), 'encoder.layer.7.output': Counter({'linear': 301989888, 'layer_norm': 491520}), 'encoder.layer.7.output.dense': Counter({'linear': 301989888}), 'encoder.layer.7.output.LayerNorm': Counter({'layer_norm': 491520}), 'encoder.layer.7.output.dropout': Counter(), 'encoder.layer.8': Counter({'linear': 905969664, 'layer_norm': 983040}), 'encoder.layer.8.attention': Counter({'linear': 301989888, 'layer_norm': 491520}), 'encoder.layer.8.attention.self': Counter({'linear': 226492416}), 'encoder.layer.8.attention.self.query': Counter({'linear': 75497472}), 'encoder.layer.8.attention.self.key': Counter({'linear': 75497472}), 'encoder.layer.8.attention.self.value': Counter({'linear': 75497472}), 'encoder.layer.8.attention.self.dropout': Counter(), 'encoder.layer.8.attention.output': Counter({'linear': 75497472, 'layer_norm': 491520}), 'encoder.layer.8.attention.output.dense': Counter({'linear': 75497472}), 'encoder.layer.8.attention.output.LayerNorm': Counter({'layer_norm': 491520}), 'encoder.layer.8.attention.output.dropout': Counter(), 'encoder.layer.8.intermediate': Counter({'linear': 301989888}), 'encoder.layer.8.intermediate.dense': Counter({'linear': 301989888}), 'encoder.layer.8.intermediate.intermediate_act_fn': Counter(), 'encoder.layer.8.output': Counter({'linear': 301989888, 'layer_norm': 491520}), 'encoder.layer.8.output.dense': Counter({'linear': 301989888}), 'encoder.layer.8.output.LayerNorm': Counter({'layer_norm': 491520}), 'encoder.layer.8.output.dropout': Counter(), 'encoder.layer.9': Counter({'linear': 905969664, 'layer_norm': 983040}), 'encoder.layer.9.attention': Counter({'linear': 301989888, 'layer_norm': 491520}), 'encoder.layer.9.attention.self': Counter({'linear': 226492416}), 'encoder.layer.9.attention.self.query': Counter({'linear': 75497472}), 'encoder.layer.9.attention.self.key': Counter({'linear': 75497472}), 'encoder.layer.9.attention.self.value': Counter({'linear': 75497472}), 'encoder.layer.9.attention.self.dropout': Counter(), 'encoder.layer.9.attention.output': Counter({'linear': 75497472, 'layer_norm': 491520}), 'encoder.layer.9.attention.output.dense': Counter({'linear': 75497472}), 'encoder.layer.9.attention.output.LayerNorm': Counter({'layer_norm': 491520}), 'encoder.layer.9.attention.output.dropout': Counter(), 'encoder.layer.9.intermediate': Counter({'linear': 301989888}), 'encoder.layer.9.intermediate.dense': Counter({'linear': 301989888}), 'encoder.layer.9.intermediate.intermediate_act_fn': Counter(), 'encoder.layer.9.output': Counter({'linear': 301989888, 'layer_norm': 491520}), 'encoder.layer.9.output.dense': Counter({'linear': 301989888}), 'encoder.layer.9.output.LayerNorm': Counter({'layer_norm': 491520}), 'encoder.layer.9.output.dropout': Counter(), 'encoder.layer.10': Counter({'linear': 905969664, 'layer_norm': 983040}), 'encoder.layer.10.attention': Counter({'linear': 301989888, 'layer_norm': 491520}), 'encoder.layer.10.attention.self': Counter({'linear': 226492416}), 'encoder.layer.10.attention.self.query': Counter({'linear': 75497472}), 'encoder.layer.10.attention.self.key': Counter({'linear': 75497472}), 'encoder.layer.10.attention.self.value': Counter({'linear': 75497472}), 'encoder.layer.10.attention.self.dropout': Counter(), 'encoder.layer.10.attention.output': Counter({'linear': 75497472, 'layer_norm': 491520}), 'encoder.layer.10.attention.output.dense': Counter({'linear': 75497472}), 'encoder.layer.10.attention.output.LayerNorm': Counter({'layer_norm': 491520}), 'encoder.layer.10.attention.output.dropout': Counter(), 'encoder.layer.10.intermediate': Counter({'linear': 301989888}), 'encoder.layer.10.intermediate.dense': Counter({'linear': 301989888}), 'encoder.layer.10.intermediate.intermediate_act_fn': Counter(), 'encoder.layer.10.output': Counter({'linear': 301989888, 'layer_norm': 491520}), 'encoder.layer.10.output.dense': Counter({'linear': 301989888}), 'encoder.layer.10.output.LayerNorm': Counter({'layer_norm': 491520}), 'encoder.layer.10.output.dropout': Counter(), 'encoder.layer.11': Counter({'linear': 905969664, 'layer_norm': 983040}), 'encoder.layer.11.attention': Counter({'linear': 301989888, 'layer_norm': 491520}), 'encoder.layer.11.attention.self': Counter({'linear': 226492416}), 'encoder.layer.11.attention.self.query': Counter({'linear': 75497472}), 'encoder.layer.11.attention.self.key': Counter({'linear': 75497472}), 'encoder.layer.11.attention.self.value': Counter({'linear': 75497472}), 'encoder.layer.11.attention.self.dropout': Counter(), 'encoder.layer.11.attention.output': Counter({'linear': 75497472, 'layer_norm': 491520}), 'encoder.layer.11.attention.output.dense': Counter({'linear': 75497472}), 'encoder.layer.11.attention.output.LayerNorm': Counter({'layer_norm': 491520}), 'encoder.layer.11.attention.output.dropout': Counter(), 'encoder.layer.11.intermediate': Counter({'linear': 301989888}), 'encoder.layer.11.intermediate.dense': Counter({'linear': 301989888}), 'encoder.layer.11.intermediate.intermediate_act_fn': Counter(), 'encoder.layer.11.output': Counter({'linear': 301989888, 'layer_norm': 491520}), 'encoder.layer.11.output.dense': Counter({'linear': 301989888}), 'encoder.layer.11.output.LayerNorm': Counter({'layer_norm': 491520}), 'encoder.layer.11.output.dropout': Counter(), 'pooler': Counter({'linear': 589824}), 'pooler.dense': Counter({'linear': 589824}), 'pooler.activation': Counter()}\n",
            "| module                                     | #parameters or shape   | #flops    |\n",
            "|:-------------------------------------------|:-----------------------|:----------|\n",
            "| model                                      | 0.109G                 | 10.885G   |\n",
            "|  embeddings                                |  23.837M               |  0.492M   |\n",
            "|   embeddings.word_embeddings               |   23.441M              |   0       |\n",
            "|    embeddings.word_embeddings.weight       |    (30522, 768)        |           |\n",
            "|   embeddings.position_embeddings           |   0.393M               |   0       |\n",
            "|    embeddings.position_embeddings.weight   |    (512, 768)          |           |\n",
            "|   embeddings.token_type_embeddings         |   1.536K               |   0       |\n",
            "|    embeddings.token_type_embeddings.weight |    (2, 768)            |           |\n",
            "|   embeddings.LayerNorm                     |   1.536K               |   0.492M  |\n",
            "|    embeddings.LayerNorm.weight             |    (768,)              |           |\n",
            "|    embeddings.LayerNorm.bias               |    (768,)              |           |\n",
            "|  encoder.layer                             |  85.054M               |  10.883G  |\n",
            "|   encoder.layer.0                          |   7.088M               |   0.907G  |\n",
            "|    encoder.layer.0.attention               |    2.364M              |    0.302G |\n",
            "|    encoder.layer.0.intermediate.dense      |    2.362M              |    0.302G |\n",
            "|    encoder.layer.0.output                  |    2.362M              |    0.302G |\n",
            "|   encoder.layer.1                          |   7.088M               |   0.907G  |\n",
            "|    encoder.layer.1.attention               |    2.364M              |    0.302G |\n",
            "|    encoder.layer.1.intermediate.dense      |    2.362M              |    0.302G |\n",
            "|    encoder.layer.1.output                  |    2.362M              |    0.302G |\n",
            "|   encoder.layer.2                          |   7.088M               |   0.907G  |\n",
            "|    encoder.layer.2.attention               |    2.364M              |    0.302G |\n",
            "|    encoder.layer.2.intermediate.dense      |    2.362M              |    0.302G |\n",
            "|    encoder.layer.2.output                  |    2.362M              |    0.302G |\n",
            "|   encoder.layer.3                          |   7.088M               |   0.907G  |\n",
            "|    encoder.layer.3.attention               |    2.364M              |    0.302G |\n",
            "|    encoder.layer.3.intermediate.dense      |    2.362M              |    0.302G |\n",
            "|    encoder.layer.3.output                  |    2.362M              |    0.302G |\n",
            "|   encoder.layer.4                          |   7.088M               |   0.907G  |\n",
            "|    encoder.layer.4.attention               |    2.364M              |    0.302G |\n",
            "|    encoder.layer.4.intermediate.dense      |    2.362M              |    0.302G |\n",
            "|    encoder.layer.4.output                  |    2.362M              |    0.302G |\n",
            "|   encoder.layer.5                          |   7.088M               |   0.907G  |\n",
            "|    encoder.layer.5.attention               |    2.364M              |    0.302G |\n",
            "|    encoder.layer.5.intermediate.dense      |    2.362M              |    0.302G |\n",
            "|    encoder.layer.5.output                  |    2.362M              |    0.302G |\n",
            "|   encoder.layer.6                          |   7.088M               |   0.907G  |\n",
            "|    encoder.layer.6.attention               |    2.364M              |    0.302G |\n",
            "|    encoder.layer.6.intermediate.dense      |    2.362M              |    0.302G |\n",
            "|    encoder.layer.6.output                  |    2.362M              |    0.302G |\n",
            "|   encoder.layer.7                          |   7.088M               |   0.907G  |\n",
            "|    encoder.layer.7.attention               |    2.364M              |    0.302G |\n",
            "|    encoder.layer.7.intermediate.dense      |    2.362M              |    0.302G |\n",
            "|    encoder.layer.7.output                  |    2.362M              |    0.302G |\n",
            "|   encoder.layer.8                          |   7.088M               |   0.907G  |\n",
            "|    encoder.layer.8.attention               |    2.364M              |    0.302G |\n",
            "|    encoder.layer.8.intermediate.dense      |    2.362M              |    0.302G |\n",
            "|    encoder.layer.8.output                  |    2.362M              |    0.302G |\n",
            "|   encoder.layer.9                          |   7.088M               |   0.907G  |\n",
            "|    encoder.layer.9.attention               |    2.364M              |    0.302G |\n",
            "|    encoder.layer.9.intermediate.dense      |    2.362M              |    0.302G |\n",
            "|    encoder.layer.9.output                  |    2.362M              |    0.302G |\n",
            "|   encoder.layer.10                         |   7.088M               |   0.907G  |\n",
            "|    encoder.layer.10.attention              |    2.364M              |    0.302G |\n",
            "|    encoder.layer.10.intermediate.dense     |    2.362M              |    0.302G |\n",
            "|    encoder.layer.10.output                 |    2.362M              |    0.302G |\n",
            "|   encoder.layer.11                         |   7.088M               |   0.907G  |\n",
            "|    encoder.layer.11.attention              |    2.364M              |    0.302G |\n",
            "|    encoder.layer.11.intermediate.dense     |    2.362M              |    0.302G |\n",
            "|    encoder.layer.11.output                 |    2.362M              |    0.302G |\n",
            "|  pooler.dense                              |  0.591M                |  0.59M    |\n",
            "|   pooler.dense.weight                      |   (768, 768)           |           |\n",
            "|   pooler.dense.bias                        |   (768,)               |           |\n",
            "N/A indicates a possibly missing statistic due to how the module was called. Missing values are still included in the parent's total.\n",
            "BertModel(\n",
            "  #params: 0.11G, #flops: 10.88G\n",
            "  (embeddings): BertEmbeddings(\n",
            "    #params: 23.84M, #flops: 0.49M\n",
            "    (word_embeddings): Embedding(\n",
            "      30522, 768, padding_idx=0\n",
            "      #params: 23.44M, #flops: 0\n",
            "    )\n",
            "    (position_embeddings): Embedding(\n",
            "      512, 768\n",
            "      #params: 0.39M, #flops: 0\n",
            "    )\n",
            "    (token_type_embeddings): Embedding(\n",
            "      2, 768\n",
            "      #params: 1.54K, #flops: 0\n",
            "    )\n",
            "    (LayerNorm): LayerNorm(\n",
            "      (768,), eps=1e-12, elementwise_affine=True\n",
            "      #params: 1.54K, #flops: 0.49M\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    #params: 85.05M, #flops: 10.88G\n",
            "    (layer): ModuleList(\n",
            "      #params: 85.05M, #flops: 10.88G\n",
            "      (0): BertLayer(\n",
            "        #params: 7.09M, #flops: 0.91G\n",
            "        (attention): BertAttention(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (self): BertSdpaSelfAttention(\n",
            "            #params: 1.77M, #flops: 0.23G\n",
            "            (query): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (key): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (value): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (dropout): Dropout(\n",
            "              p=0.1, inplace=False\n",
            "              #params: 0, #flops: N/A\n",
            "            )\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            #params: 0.59M, #flops: 75.99M\n",
            "            (dense): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (LayerNorm): LayerNorm(\n",
            "              (768,), eps=1e-12, elementwise_affine=True\n",
            "              #params: 1.54K, #flops: 0.49M\n",
            "            )\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (dense): Linear(\n",
            "            in_features=768, out_features=3072, bias=True\n",
            "            #params: 2.36M, #flops: 0.3G\n",
            "          )\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (dense): Linear(\n",
            "            in_features=3072, out_features=768, bias=True\n",
            "            #params: 2.36M, #flops: 0.3G\n",
            "          )\n",
            "          (LayerNorm): LayerNorm(\n",
            "            (768,), eps=1e-12, elementwise_affine=True\n",
            "            #params: 1.54K, #flops: 0.49M\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): BertLayer(\n",
            "        #params: 7.09M, #flops: 0.91G\n",
            "        (attention): BertAttention(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (self): BertSdpaSelfAttention(\n",
            "            #params: 1.77M, #flops: 0.23G\n",
            "            (query): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (key): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (value): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (dropout): Dropout(\n",
            "              p=0.1, inplace=False\n",
            "              #params: 0, #flops: N/A\n",
            "            )\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            #params: 0.59M, #flops: 75.99M\n",
            "            (dense): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (LayerNorm): LayerNorm(\n",
            "              (768,), eps=1e-12, elementwise_affine=True\n",
            "              #params: 1.54K, #flops: 0.49M\n",
            "            )\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (dense): Linear(\n",
            "            in_features=768, out_features=3072, bias=True\n",
            "            #params: 2.36M, #flops: 0.3G\n",
            "          )\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (dense): Linear(\n",
            "            in_features=3072, out_features=768, bias=True\n",
            "            #params: 2.36M, #flops: 0.3G\n",
            "          )\n",
            "          (LayerNorm): LayerNorm(\n",
            "            (768,), eps=1e-12, elementwise_affine=True\n",
            "            #params: 1.54K, #flops: 0.49M\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): BertLayer(\n",
            "        #params: 7.09M, #flops: 0.91G\n",
            "        (attention): BertAttention(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (self): BertSdpaSelfAttention(\n",
            "            #params: 1.77M, #flops: 0.23G\n",
            "            (query): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (key): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (value): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (dropout): Dropout(\n",
            "              p=0.1, inplace=False\n",
            "              #params: 0, #flops: N/A\n",
            "            )\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            #params: 0.59M, #flops: 75.99M\n",
            "            (dense): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (LayerNorm): LayerNorm(\n",
            "              (768,), eps=1e-12, elementwise_affine=True\n",
            "              #params: 1.54K, #flops: 0.49M\n",
            "            )\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (dense): Linear(\n",
            "            in_features=768, out_features=3072, bias=True\n",
            "            #params: 2.36M, #flops: 0.3G\n",
            "          )\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (dense): Linear(\n",
            "            in_features=3072, out_features=768, bias=True\n",
            "            #params: 2.36M, #flops: 0.3G\n",
            "          )\n",
            "          (LayerNorm): LayerNorm(\n",
            "            (768,), eps=1e-12, elementwise_affine=True\n",
            "            #params: 1.54K, #flops: 0.49M\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (3): BertLayer(\n",
            "        #params: 7.09M, #flops: 0.91G\n",
            "        (attention): BertAttention(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (self): BertSdpaSelfAttention(\n",
            "            #params: 1.77M, #flops: 0.23G\n",
            "            (query): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (key): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (value): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (dropout): Dropout(\n",
            "              p=0.1, inplace=False\n",
            "              #params: 0, #flops: N/A\n",
            "            )\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            #params: 0.59M, #flops: 75.99M\n",
            "            (dense): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (LayerNorm): LayerNorm(\n",
            "              (768,), eps=1e-12, elementwise_affine=True\n",
            "              #params: 1.54K, #flops: 0.49M\n",
            "            )\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (dense): Linear(\n",
            "            in_features=768, out_features=3072, bias=True\n",
            "            #params: 2.36M, #flops: 0.3G\n",
            "          )\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (dense): Linear(\n",
            "            in_features=3072, out_features=768, bias=True\n",
            "            #params: 2.36M, #flops: 0.3G\n",
            "          )\n",
            "          (LayerNorm): LayerNorm(\n",
            "            (768,), eps=1e-12, elementwise_affine=True\n",
            "            #params: 1.54K, #flops: 0.49M\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (4): BertLayer(\n",
            "        #params: 7.09M, #flops: 0.91G\n",
            "        (attention): BertAttention(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (self): BertSdpaSelfAttention(\n",
            "            #params: 1.77M, #flops: 0.23G\n",
            "            (query): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (key): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (value): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (dropout): Dropout(\n",
            "              p=0.1, inplace=False\n",
            "              #params: 0, #flops: N/A\n",
            "            )\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            #params: 0.59M, #flops: 75.99M\n",
            "            (dense): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (LayerNorm): LayerNorm(\n",
            "              (768,), eps=1e-12, elementwise_affine=True\n",
            "              #params: 1.54K, #flops: 0.49M\n",
            "            )\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (dense): Linear(\n",
            "            in_features=768, out_features=3072, bias=True\n",
            "            #params: 2.36M, #flops: 0.3G\n",
            "          )\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (dense): Linear(\n",
            "            in_features=3072, out_features=768, bias=True\n",
            "            #params: 2.36M, #flops: 0.3G\n",
            "          )\n",
            "          (LayerNorm): LayerNorm(\n",
            "            (768,), eps=1e-12, elementwise_affine=True\n",
            "            #params: 1.54K, #flops: 0.49M\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (5): BertLayer(\n",
            "        #params: 7.09M, #flops: 0.91G\n",
            "        (attention): BertAttention(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (self): BertSdpaSelfAttention(\n",
            "            #params: 1.77M, #flops: 0.23G\n",
            "            (query): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (key): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (value): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (dropout): Dropout(\n",
            "              p=0.1, inplace=False\n",
            "              #params: 0, #flops: N/A\n",
            "            )\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            #params: 0.59M, #flops: 75.99M\n",
            "            (dense): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (LayerNorm): LayerNorm(\n",
            "              (768,), eps=1e-12, elementwise_affine=True\n",
            "              #params: 1.54K, #flops: 0.49M\n",
            "            )\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (dense): Linear(\n",
            "            in_features=768, out_features=3072, bias=True\n",
            "            #params: 2.36M, #flops: 0.3G\n",
            "          )\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (dense): Linear(\n",
            "            in_features=3072, out_features=768, bias=True\n",
            "            #params: 2.36M, #flops: 0.3G\n",
            "          )\n",
            "          (LayerNorm): LayerNorm(\n",
            "            (768,), eps=1e-12, elementwise_affine=True\n",
            "            #params: 1.54K, #flops: 0.49M\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (6): BertLayer(\n",
            "        #params: 7.09M, #flops: 0.91G\n",
            "        (attention): BertAttention(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (self): BertSdpaSelfAttention(\n",
            "            #params: 1.77M, #flops: 0.23G\n",
            "            (query): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (key): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (value): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (dropout): Dropout(\n",
            "              p=0.1, inplace=False\n",
            "              #params: 0, #flops: N/A\n",
            "            )\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            #params: 0.59M, #flops: 75.99M\n",
            "            (dense): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (LayerNorm): LayerNorm(\n",
            "              (768,), eps=1e-12, elementwise_affine=True\n",
            "              #params: 1.54K, #flops: 0.49M\n",
            "            )\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (dense): Linear(\n",
            "            in_features=768, out_features=3072, bias=True\n",
            "            #params: 2.36M, #flops: 0.3G\n",
            "          )\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (dense): Linear(\n",
            "            in_features=3072, out_features=768, bias=True\n",
            "            #params: 2.36M, #flops: 0.3G\n",
            "          )\n",
            "          (LayerNorm): LayerNorm(\n",
            "            (768,), eps=1e-12, elementwise_affine=True\n",
            "            #params: 1.54K, #flops: 0.49M\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (7): BertLayer(\n",
            "        #params: 7.09M, #flops: 0.91G\n",
            "        (attention): BertAttention(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (self): BertSdpaSelfAttention(\n",
            "            #params: 1.77M, #flops: 0.23G\n",
            "            (query): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (key): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (value): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (dropout): Dropout(\n",
            "              p=0.1, inplace=False\n",
            "              #params: 0, #flops: N/A\n",
            "            )\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            #params: 0.59M, #flops: 75.99M\n",
            "            (dense): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (LayerNorm): LayerNorm(\n",
            "              (768,), eps=1e-12, elementwise_affine=True\n",
            "              #params: 1.54K, #flops: 0.49M\n",
            "            )\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (dense): Linear(\n",
            "            in_features=768, out_features=3072, bias=True\n",
            "            #params: 2.36M, #flops: 0.3G\n",
            "          )\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (dense): Linear(\n",
            "            in_features=3072, out_features=768, bias=True\n",
            "            #params: 2.36M, #flops: 0.3G\n",
            "          )\n",
            "          (LayerNorm): LayerNorm(\n",
            "            (768,), eps=1e-12, elementwise_affine=True\n",
            "            #params: 1.54K, #flops: 0.49M\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (8): BertLayer(\n",
            "        #params: 7.09M, #flops: 0.91G\n",
            "        (attention): BertAttention(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (self): BertSdpaSelfAttention(\n",
            "            #params: 1.77M, #flops: 0.23G\n",
            "            (query): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (key): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (value): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (dropout): Dropout(\n",
            "              p=0.1, inplace=False\n",
            "              #params: 0, #flops: N/A\n",
            "            )\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            #params: 0.59M, #flops: 75.99M\n",
            "            (dense): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (LayerNorm): LayerNorm(\n",
            "              (768,), eps=1e-12, elementwise_affine=True\n",
            "              #params: 1.54K, #flops: 0.49M\n",
            "            )\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (dense): Linear(\n",
            "            in_features=768, out_features=3072, bias=True\n",
            "            #params: 2.36M, #flops: 0.3G\n",
            "          )\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (dense): Linear(\n",
            "            in_features=3072, out_features=768, bias=True\n",
            "            #params: 2.36M, #flops: 0.3G\n",
            "          )\n",
            "          (LayerNorm): LayerNorm(\n",
            "            (768,), eps=1e-12, elementwise_affine=True\n",
            "            #params: 1.54K, #flops: 0.49M\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (9): BertLayer(\n",
            "        #params: 7.09M, #flops: 0.91G\n",
            "        (attention): BertAttention(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (self): BertSdpaSelfAttention(\n",
            "            #params: 1.77M, #flops: 0.23G\n",
            "            (query): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (key): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (value): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (dropout): Dropout(\n",
            "              p=0.1, inplace=False\n",
            "              #params: 0, #flops: N/A\n",
            "            )\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            #params: 0.59M, #flops: 75.99M\n",
            "            (dense): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (LayerNorm): LayerNorm(\n",
            "              (768,), eps=1e-12, elementwise_affine=True\n",
            "              #params: 1.54K, #flops: 0.49M\n",
            "            )\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (dense): Linear(\n",
            "            in_features=768, out_features=3072, bias=True\n",
            "            #params: 2.36M, #flops: 0.3G\n",
            "          )\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (dense): Linear(\n",
            "            in_features=3072, out_features=768, bias=True\n",
            "            #params: 2.36M, #flops: 0.3G\n",
            "          )\n",
            "          (LayerNorm): LayerNorm(\n",
            "            (768,), eps=1e-12, elementwise_affine=True\n",
            "            #params: 1.54K, #flops: 0.49M\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (10): BertLayer(\n",
            "        #params: 7.09M, #flops: 0.91G\n",
            "        (attention): BertAttention(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (self): BertSdpaSelfAttention(\n",
            "            #params: 1.77M, #flops: 0.23G\n",
            "            (query): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (key): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (value): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (dropout): Dropout(\n",
            "              p=0.1, inplace=False\n",
            "              #params: 0, #flops: N/A\n",
            "            )\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            #params: 0.59M, #flops: 75.99M\n",
            "            (dense): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (LayerNorm): LayerNorm(\n",
            "              (768,), eps=1e-12, elementwise_affine=True\n",
            "              #params: 1.54K, #flops: 0.49M\n",
            "            )\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (dense): Linear(\n",
            "            in_features=768, out_features=3072, bias=True\n",
            "            #params: 2.36M, #flops: 0.3G\n",
            "          )\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (dense): Linear(\n",
            "            in_features=3072, out_features=768, bias=True\n",
            "            #params: 2.36M, #flops: 0.3G\n",
            "          )\n",
            "          (LayerNorm): LayerNorm(\n",
            "            (768,), eps=1e-12, elementwise_affine=True\n",
            "            #params: 1.54K, #flops: 0.49M\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (11): BertLayer(\n",
            "        #params: 7.09M, #flops: 0.91G\n",
            "        (attention): BertAttention(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (self): BertSdpaSelfAttention(\n",
            "            #params: 1.77M, #flops: 0.23G\n",
            "            (query): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (key): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (value): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (dropout): Dropout(\n",
            "              p=0.1, inplace=False\n",
            "              #params: 0, #flops: N/A\n",
            "            )\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            #params: 0.59M, #flops: 75.99M\n",
            "            (dense): Linear(\n",
            "              in_features=768, out_features=768, bias=True\n",
            "              #params: 0.59M, #flops: 75.5M\n",
            "            )\n",
            "            (LayerNorm): LayerNorm(\n",
            "              (768,), eps=1e-12, elementwise_affine=True\n",
            "              #params: 1.54K, #flops: 0.49M\n",
            "            )\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (dense): Linear(\n",
            "            in_features=768, out_features=3072, bias=True\n",
            "            #params: 2.36M, #flops: 0.3G\n",
            "          )\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          #params: 2.36M, #flops: 0.3G\n",
            "          (dense): Linear(\n",
            "            in_features=3072, out_features=768, bias=True\n",
            "            #params: 2.36M, #flops: 0.3G\n",
            "          )\n",
            "          (LayerNorm): LayerNorm(\n",
            "            (768,), eps=1e-12, elementwise_affine=True\n",
            "            #params: 1.54K, #flops: 0.49M\n",
            "          )\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    #params: 0.59M, #flops: 0.59M\n",
            "    (dense): Linear(\n",
            "      in_features=768, out_features=768, bias=True\n",
            "      #params: 0.59M, #flops: 0.59M\n",
            "    )\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    }
  ]
}